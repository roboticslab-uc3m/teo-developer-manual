{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#teo-developer-manual","title":"TEO Developer Manual","text":"<p>TEO Developer Manual @ roboticslab-uc3m</p> <p>Click on the option you want, or use the <code>P</code> and <code>N</code> keys to navigate through the sections (Previous, Next).</p>"},{"location":"index.html#additional-notes","title":"Additional notes","text":"<ul> <li>The content of this documentation is generated from files hosted on GitHub.</li> </ul>"},{"location":"index.html#if-you-have-any-doubts-or-comments","title":"If you have any doubts or comments","text":"<p>Please read the Developer Manual's Asking Questions section, and once you've succeded with its self-evaluation follow the recommendations by commenting publicly HERE if required</p>"},{"location":"additional-resources.html","title":"Additional Resources","text":""},{"location":"additional-resources.html#additional-resources","title":"Additional Resources","text":"<p>Put an issue if you have any doubts!</p>"},{"location":"additional-resources.html#old-and-broken","title":"Old and broken","text":"<ul> <li>Excel:\u00a0Drivers Check</li> <li>Logbook</li> </ul>"},{"location":"architecture.html","title":"Cognitive Architecture","text":""},{"location":"architecture.html#cognitive-architecture","title":"Cognitive Architecture","text":"<p>Conventionally, we have said that there is technically no fixed software architecture for TEO. We use YARP to implement a loosely coupled program and library infrastructure as described by the Component-Based Software Engineering (CBSE) paradigm. XML files describe modules and connections, which can be administered throughout the TEO cluster manually or using a program called yarpmanager. During normal operation:</p> <ol> <li>The teoBase XML is launched for basic robot services.</li> <li>The teoTools XML is launched to assure correct operation of each teoBase service.</li> <li>A final application-level XML is launched, from one of the demonstration or research repositories.</li> </ol> <p>A traditional setup of the components for an application involving gaze control and manipulator gesture, extracted from the teo-follow-me demonstration repository, is depicted below.</p> <p></p> <p>More recently, the TEO Cognitive Architecture has gained similarities to the ICub Cognitive Architecture and TRoPOCALs, as well as many other bio-inspired embodied cognition architectures.</p> <p>We highlight the following aspects:</p> <ul> <li>A Decision Making (DM) process is governed by managing a-priori knowledge, short and long term memory, and instantaneous attention mechanisms.</li> <li>The DM directly operates in the robot motor actuation space of manipulation, locomotion and gaze control.</li> <li>Attention spans from multimodal perceptual aural, visual, and proprioceptive sensory data.</li> <li>Linguistic input is partially processed from the attention mechanism and also fed into the DM.</li> <li>An optional reactive component can be activated, enabling a pathway that directly maps from the sensor data to the motor space.</li> </ul> <p></p>"},{"location":"connectors.html","title":"Connectors","text":""},{"location":"connectors.html#connectors","title":"Connectors","text":"Emergency Buttons Connectors JR3 Circuit Connectors Technosoft IPos Connectors Cui Absolute Circuit Connectors CAN Bus Connector Internal Router Connectors iPOS RS232 Connector"},{"location":"contributors.html","title":"Contributors","text":""},{"location":"contributors.html#contributors","title":"Contributors","text":"<p>This is a (roughly) chronological list of people who contributed to the design and development of core TEO's components (thus not accounting for research and algorithms).</p> <ul> <li> <p>Electromechanical design and maintenance:</p> <ul> <li>Santiago Mart\u00ednez (@smcdiaz)</li> <li>Juan Miguel Garc\u00eda Haro (@jmgarciah)</li> <li>Pedro Portalat\u00edn</li> <li>Jorge Mu\u00f1oz (@munozyanez)</li> <li>Alberto Rodr\u00edguez Sanz (@AlbertoRodriguezSanz)</li> <li>Pilar Maldonado (@Pilibel10)</li> </ul> </li> <li> <p>Software implementation and maintenance:</p> <ul> <li>Iv\u00e1n Monteagudo Garc\u00eda</li> <li>Juan G. V\u00edctores (@jgvictores)</li> <li>Bartek \u0141ukawski (@PeterBowman)</li> <li>Elisabeth Men\u00e9ndez (@elisabeth-ms)</li> <li>Jaime Mas Santill\u00e1n (@TheArmega)</li> </ul> </li> <li> <p>Firmware and peripherals:</p> <ul> <li>Lacquey Fetch gripper:<ul> <li>V\u00edctor C\u00e9sar Sanz Labella</li> </ul> </li> <li>Absolute encoders (CUI):<ul> <li>Rom\u00e1n Avell\u00e1n Mart\u00edn</li> </ul> </li> <li>JR3 force-torque sensors:<ul> <li>Alberto L\u00f3pez Esteban</li> <li>Bartek \u0141ukawski (@PeterBowman)</li> </ul> </li> <li>Dextra hand:<ul> <li>\u00c1lvaro Villoslada (@Alvipe)</li> <li>Jennifer J. Gago (@jgagom)</li> </ul> </li> <li>Flea3 camera:<ul> <li>David Est\u00e9vez Fern\u00e1ndez (@David-Estevez)</li> </ul> </li> </ul> </li> <li> <p>Simulation:</p> <ul> <li>OpenRAVE:<ul> <li>Juan G. V\u00edctores (@jgvictores)</li> <li>Jorge Mu\u00f1oz (@munozyanez)</li> </ul> </li> <li>Gazebo:<ul> <li>Ra\u00fal Fern\u00e1ndez-Fern\u00e1ndez (@RaulFdzbis)</li> <li>Bartek \u0141ukawski (@PeterBowman)</li> </ul> </li> <li>Simox:<ul> <li>\u00c1lvaro Mart\u00ednez (@AlvaroMartinezR)</li> </ul> </li> <li>PyBullet:<ul> <li>Ignacio Montesino Valle (@imontesino)</li> </ul> </li> <li>CoppeliaSim:<ul> <li>Juan G. V\u00edctores (@jgvictores)</li> </ul> </li> <li>Webots:<ul> <li>Juan G. V\u00edctores (@jgvictores)</li> </ul> </li> </ul> </li> </ul>"},{"location":"demo-procedure.html","title":"Demo Procedure","text":""},{"location":"demo-procedure.html#demo-procedure","title":"Demo Procedure","text":""},{"location":"demo-procedure.html#preparation","title":"Preparation","text":"<ol> <li>Remove any obstacles (table, curtains, chairs... or other objects that may interfere).</li> <li>Place the robot in a position where it can have space and cannot hit any obstacle.</li> <li>Make sure all emergency stop buttons (main and per robot part) are closed.</li> <li>Turn on both 42V power supplies (check they are actually at 42V before proceeding further) and open the main emergency button.</li> <li>On the rear panel of the robot, press the \"General\" red button first. The button should light up. For the demo we will also need to press the CABEZA CPU, MANIPULADOR CPU, MANIPULADOR DERECHO, MANIPULADOR IZQUIERDO. </li> <li>Press other relevant buttons and make sure they light up: manipulation PC and the robot parts you want to use.</li> <li>Turn on the manipulation PC (the PC is in the right side of the chest, to turn it on you have to take the long grey cable with red in it and make a  short circuit with the connecter of the cable and the metalic part of TEO).</li> <li>Turn on the head PC (the PC is the center of the chest and it has a small button on the right side).</li> <li>Wait until the manipulation PC and head PC have finished booting. You can monitor this through <code>ping manipulation</code> and <code>ping head</code> issued from another PC connected to the robot's local network.</li> <li>Connect by ssh to <code>ssh manipulation</code> and <code>ssh head</code>.</li> <li> <p>Open the emergency buttons for the robot parts you need. Keep these buttons close and ready to be used.</p> </li> <li> <p>If you want to try a specific part of TEO, in manipulation PC run <code>launchCanBus --from launchCanBus/(specific part that you wanna try)</code>.</p> </li> <li>In another terminar in manipulation PC run <code>yarp rpc /teo/(specific part that you wanna try)/rpc:i</code>.</li> <li>Run the yarp commands like <code>set pos 0 -25</code> </li> </ol>"},{"location":"demo-procedure.html#demonstration-instructions","title":"Demonstration Instructions","text":"<p>Refer to the specific instructions of the demo you want to launch:</p> <ul> <li>teo-self-presentation</li> <li>teo-follow-me</li> <li>teo-waiter</li> <li>teo-demos-misc</li> </ul>"},{"location":"demo-procedure.html#see-also","title":"See also","text":"<ul> <li>driver check procedure</li> <li>wiki: Qu\u00e9 llevar a Demos (TEO)</li> </ul>"},{"location":"diagrams.html","title":"Diagrams","text":""},{"location":"diagrams.html#diagrams","title":"Diagrams","text":""},{"location":"diagrams.html#joint-indexes","title":"Joint Indexes","text":"Joint Indexes (CAN bus) Joint Indexes (YARP ports)"},{"location":"diagrams.html#joint-directions-of-rotation","title":"Joint Directions of Rotation","text":"Joint Directions of Rotation"},{"location":"diagrams.html#dh-coordinate-systems","title":"DH Coordinate Systems","text":""},{"location":"diagrams.html#link-lengths","title":"Link Lengths","text":""},{"location":"diagrams.html#link-names","title":"Link Names","text":"<pre><code>graph TD\n\n%% head and some trunk\nFrontalNeck[FrontalNeck]\nAxialNeck[AxialNeck]\nFrontalNeck--&gt;|FrontalNeck| AxialNeck\n\nFrontalTrunk[FrontalTrunk]\nAxialNeck--&gt;|AxialNeck|FrontalTrunk\n\n\n%% rightArm\nFrontalRightShoulder[FrontalRightShoulder]\nFrontalTrunk--&gt;|FrontalRightShoulder|FrontalRightShoulder\n\nSagittalRightShoulder[SagittalRightShoulder]\nFrontalRightShoulder--&gt;|SagittalRightShoulder|SagittalRightShoulder\n\nAxialRightShoulder[AxialRightShoulder]\nSagittalRightShoulder--&gt;|AxialRightShoulder|AxialRightShoulder\n\nFrontalRightElbow[FrontalRightElbow]\nAxialRightShoulder--&gt;|FrontalRightElbow|FrontalRightElbow\n\nAxialRightWrist[AxialRightWrist]\nFrontalRightElbow--&gt;|AxialRightWrist|AxialRightWrist\n\nFrontalRightWrist[FrontalRightWrist]\nAxialRightWrist--&gt;|FrontalRightWrist|FrontalRightWrist\n\n\n%% more trunk\nAxialTrunk[AxialTrunk]\nFrontalTrunk--&gt;|FrontalTrunk|AxialTrunk\n\nRoot[Root]\nAxialTrunk--&gt;|AxialTrunk|Root\n\n\n%% rightLeg\nAxialRightHip[AxialRightHip]\nRoot--&gt;|AxialRightHip|AxialRightHip\n\nSagittalRightHip[SagittalRightHip]\nAxialRightHip--&gt;|SagittalRightHip|SagittalRightHip\n\nFrontalRightHip[FrontalRightHip]\nSagittalRightHip--&gt;|FrontalRightHip|FrontalRightHip\n\nFrontalRightKnee[FrontalRightKnee]\nFrontalRightHip--&gt;|FrontalRightKnee|FrontalRightKnee\n\nFrontalRightAnkle[FrontalRightAnkle]\nFrontalRightKnee--&gt;|FrontalRightAnkle|FrontalRightAnkle\n\nSagittalRightAnkle[SagittalRightAnkle]\nFrontalRightAnkle--&gt;|SagittalRightAnkle|SagittalRightAnkle\n\n\n%% leftLeg\nAxialLeftHip[AxialLeftHip]\nRoot--&gt;|AxialLeftHip|AxialLeftHip\n\nSagittalLeftHip[SagittalLeftHip]\nAxialLeftHip--&gt;|SagittalLeftHip|SagittalLeftHip\n\nFrontalLeftHip[FrontalLeftHip]\nSagittalLeftHip--&gt;|FrontalLeftHip|FrontalLeftHip\n\nFrontalLeftKnee[FrontalLeftKnee]\nFrontalLeftHip--&gt;|FrontalLeftKnee|FrontalLeftKnee\n\nFrontalLeftAnkle[FrontalLeftAnkle]\nFrontalLeftKnee--&gt;|FrontalLeftAnkle|FrontalLeftAnkle\n\nSagittalLeftAnkle[SagittalLeftAnkle]\nFrontalLeftAnkle--&gt;|SagittalLeftAnkle|SagittalLeftAnkle\n\n\n%% leftArm\nFrontalLeftShoulder[FrontalLeftShoulder]\nFrontalTrunk--&gt;|FrontalLeftShoulder|FrontalLeftShoulder\n\nSagittalLeftShoulder[SagittalLeftShoulder]\nFrontalLeftShoulder--&gt;|SagittalLeftShoulder|SagittalLeftShoulder\n\nAxialLeftShoulder[AxialLeftShoulder]\nSagittalLeftShoulder--&gt;|AxialLeftShoulder|AxialLeftShoulder\n\nFrontalLeftElbow[FrontalLeftElbow]\nAxialLeftShoulder--&gt;|FrontalLeftElbow|FrontalLeftElbow\n\nAxialLeftWrist[AxialLeftWrist]\nFrontalLeftElbow--&gt;|AxialLeftWrist|AxialLeftWrist\n\nFrontalLeftWrist[FrontalLeftWrist]\nAxialLeftWrist--&gt;|FrontalLeftWrist|FrontalLeftWrist\n</code></pre> <p>teo-link-names.pdf</p> <p></p>"},{"location":"diagrams.html#cogs","title":"COGs","text":"COGs"},{"location":"diagrams.html#ft-sensors","title":"F/T sensors","text":""},{"location":"diagrams.html#ft-sensors-ports-channels-and-coordinate-systems","title":"F/T sensors (Ports, channels and coordinate systems)","text":"F/T sensors (Ports and channels)"},{"location":"diagrams.html#ft-sensors-mechanical","title":"F/T sensors (Mechanical)","text":"<p>Jr3 50M31 corregido.pdf</p> <p></p>"},{"location":"diagrams.html#lacquey-fetch","title":"Lacquey Fetch","text":"<p>This sketches were made with SolidWorks in order to provide the position of the next joints, in this case the fingers from the origin of the hand, not to provide detailed mechanical annotations for the hand.</p>"},{"location":"diagrams.html#lacquey-fetch-hand","title":"Lacquey Fetch (Hand)","text":"<p>fetch-hand.pdf</p> <p></p>"},{"location":"diagrams.html#lacquey-fetch-proximal-falange","title":"Lacquey Fetch (Proximal Falange)","text":"<p>fetch-proximal-falange.pdf</p> <p></p>"},{"location":"driver-check-procedure.html","title":"Driver Check Procedure","text":""},{"location":"driver-check-procedure.html#driver-check-procedure","title":"Driver Check Procedure","text":""},{"location":"driver-check-procedure.html#startup-and-communications","title":"Startup and Communications","text":"<p>Basic steps to power things up and check the drivers of the robot:</p> <ol> <li>Make sure all emergency stop buttons (main and per robot part) are closed.</li> <li>Turn on both 42V power supplies (check they are actually at 42V before proceeding further) and open the main emergency button.</li> <li>On the rear panel of the robot, press the \"General\" red button first. The button should light up.</li> <li>Press other relevant buttons and make sure they light up: manipulation PC and the desired robot part.</li> <li>Turn on the manipulation PC.</li> <li>Wait until the manipulation PC has finished booting. You can monitor this through <code>ping manipulation</code> issued from another PC connected to the robot's local network.</li> <li>Issue <code>ssh teo@manipulation</code> from said external PC (alternatively: <code>ssh teo@2.2.2.51</code>).</li> <li>Identify the desired CAN bus interface (check our diagrams).</li> <li>For instance, to check the right arm, issue <code>candump can2</code>.</li> <li>Open the emergency button corresponding to said robot part (arms).</li> <li>Check that the status LEDs on all iPOS drives are green.</li> <li>Otherwise, a red LED would usually hint a communication problem. In that case, close the emergency button and review all CAN connectors (usually it is enough to press them a bit harder), then check again.</li> <li>At the same time the emergency button was opened, you should see the boot-up CAN messages issued by the drives showing up in the terminal, one per drive, using a COB-ID of the form 714 (hexadecimal), where 700h is the command specifier and 14h (=20) the drive ID (refer to our diagrams and mind the hex-to-decimal conversion).</li> <li>If any bootup message is missing, this means the drive is not communicating properly. Close the emergency button and check the CAN connectors. You can isolate the problem by disconnecting downstream drives, i.e. leaving only the relevant drives connected to the bus, including the faulty one. Once fixed, with <code>candump</code> still running, open the emergency button and check the newly generated bootup messages.</li> </ol>"},{"location":"driver-check-procedure.html#joint-motion","title":"Joint Motion","text":"<p>Once all connection issues (if present) have been sorted out, you can proceed to performing joint motion:</p> <ol> <li>Assuming we want to send joint commands to the right arm, while still logged in via SSH to the manipulation PC: <code>launchCanBus --from manipulation-rightArm.ini</code>.</li> <li>Identify any errors, if present. The controller has restart mechanisms that may attempt to recover from errors and may or may not succeed.</li> <li>Absolute encoders are prone to fail. They are given a fixed number of retries. If it is not possible to establish communication, the YARP plugin related to this iPOS drive and encoder also fails on initialization. Terminate the <code>launchCanBus</code> process and try again.</li> <li>On either the robot's PC through another SSH session or on an external PC connected to the robot's local network, issue <code>yarp rpc /teo/rightArm/rpc:i</code>.</li> <li>On startup, robot joints should be set in position control mode. Within the RPC session, issue <code>get icmd cmds</code>. This should return a list of <code>pos</code> vocabs.</li> <li>If any vocab is not equal to <code>pos</code> (usually in case of failure its value is <code>cfgn</code>, which means \"not configured\"), identify the error in the console output.</li> <li>Make sure there are no obstacles ahead (including the robot itself) and identify the desired joint index in the diagrams. For instance, to move the fourth joint to -90 degrees, issue <code>set pos 3 -90</code>.</li> </ol>"},{"location":"driver-check-procedure.html#shutdown","title":"Shutdown","text":"<p>To shut everything down:</p> <ol> <li>Close all emergency buttons apart from the main one (next to the power supplies).</li> <li>While still logged in via SSH to the relevant PC, issue <code>sudo shutdown -h now</code>. Your SSH connection should close automatically.</li> <li>Turn off the \"General\" button on the rear panel of the robot.</li> <li>Close the main emergency button and turn off the 42V power supplies.</li> </ol>"},{"location":"driver-check-procedure.html#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Prior to attempting any communications through YARP with the robot, make sure your PC is connected to the same local network and it can see the YARP master on the robot's PC. You can check this by issuing <code>yarp detect --write</code> on your PC. If not successful, type <code>yarp conf 2.2.2.51 10000</code> and try again. Issue <code>yarp name list</code> to confirm you can see <code>/root</code> and <code>/manipulation</code> ports.</li> <li>Sometimes, the CAN controller on the robot PC might need a restart due to accumulating too many RX or TX CAN errors. Check this via <code>sudo ip -details link show can2</code>. If in \"ERROR-PASSIVE\" mode (i.e. any counter has reached 128 errors), restart the controller via <code>sudo systemctl restart can2</code>.</li> <li>If any absolute encoders keeps throwing timeout errors via <code>launchCanBus</code>, you can disable it by commenting out (with <code>//</code>) the <code>externalEncoder</code> line in the corresponding idxx-ipos.ini file, where xx is the CAN ID of the associated iPOS drive. This INI file can be found in <code>~/teo/nodes/</code>. Keep in mind the initial position of the joint on startup will be reported as the absolute zero position by the encoder, so you will either have to manually set the joint to zero position before starting any motion, or move it via RPC commands and trick the drive into thinking the current position is the new zero (via <code>set enc j 0</code>, where <code>j</code> is the joint index).</li> <li>An \"encoder broken wire\" error reported by <code>launchCanBus</code> means that the physical connection between the specified iPOS drive and the relative encoder is faulty. Check the cable (could be reversed or damaged), the connector and/or the encoder itself.</li> </ul>"},{"location":"driver-check-procedure.html#see-also","title":"See also","text":"<ul> <li>YARP RPC cheatsheet</li> <li>teo-hardware-issues: report any hardware-related issues here!</li> </ul>"},{"location":"dynamic-information.html","title":"Dynamic Information","text":""},{"location":"dynamic-information.html#dynamic-information","title":"Dynamic Information","text":"<p>TEO global dynamic information.</p> <p>This file contains the center of mass of the whole robot in the initial home position. For individual CoM information go here: .</p> <p>All the information presented here was calculated using SolidWorks and tuned to the real robot.</p> <p>Mass = 55900.00 g</p> <p>Volume = 48633056.11 mm\u00b3</p> <p>Center of mass: ( millimeters )</p> <pre><code>X = 8.67\n\nY = -0.03\n\nZ = 14.06\n</code></pre> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code> Ix = ( 0.02,  0.00,  1.00)     Px = 2282209291.83\n\n Iy = ( 0.00, -1.00,  0.00)     Py = 13043664521.24\n\n Iz = ( 1.00,  0.00, -0.02)     Pz = 15102428756.37\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 15098875242.10    Lxy = -827254.57    Lxz = 213401208.45\n\nLyx = -827254.57    Lyy = 13043664787.39    Lyz = -762897.83\n\nLzx = 213401208.45  Lzy = -762897.83    Lzz = 2285762539.95\n</code></pre>"},{"location":"dynamic-information.html#head","title":"HEAD","text":""},{"location":"dynamic-information.html#axialneck","title":"AxialNeck","text":"<p>Mass = 1000.00 g</p> <p>Volume = 298647.65 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code> Ix = ( 0.00,  0.00,  1.00)     Px = 528125.00\n\n Iy = ( 0.00, -1.00,  0.00)     Py = 939062.50\n\n Iz = ( 1.00,  0.00,  0.00)     Pz = 939062.50\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 939062.50     Lxy = 0.00      Lxz = 0.00\n\nLyx = 0.00      Lyy = 939062.50     Lyz = 0.00\n\nLzx = 0.00      Lzy = 0.00      Lzz = 528125.00\n</code></pre>"},{"location":"dynamic-information.html#frontalneck","title":"FrontalNeck","text":"<p>Mass = 2000.00 g</p> <p>Volume = 3869318.16 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 1.00,  0.00,  0.02)      Px = 7598184.97\n\nIy = ( 0.00,  1.00,  0.00)      Py = 8325272.78\n\nIz = (-0.02,  0.00,  1.00)      Pz = 11404600.84\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 7599321.84    Lxy = 5.83      Lxz = 65773.25\n\nLyx = 5.83      Lyy = 8325272.78    Lyz = -7.43\n\nLzx = 65773.25      Lzy = -7.43     Lzz = 11403463.96\n</code></pre>"},{"location":"dynamic-information.html#trunk","title":"TRUNK","text":""},{"location":"dynamic-information.html#frontalwaist","title":"FrontalWaist","text":"<p>Mass = 14235.45 g</p> <p>Volume = 14791096.67 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00, -1.00, -0.01)      Px = 126525199.05\n\nIy = (-0.16,  0.01, -0.99)      Py = 261470522.58\n\nIz = ( 0.99,  0.00, -0.16)      Pz = 337560229.11\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 335665140.35  Lxy = 162126.65     Lxz = 11858220.70\n\nLyx = 162126.65     Lyy = 126531585.32  Lyz = 914091.01\n\nLzx = 11858220.70   Lzy = 914091.01     Lzz = 263359225.06\n</code></pre>"},{"location":"dynamic-information.html#axialwaist","title":"AxialWaist","text":"<p>Mass = 1000.00 g</p> <p>Volume = 141815.56 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00, -1.00,  0.01)      Px = 899709.63\n\nIy = (-0.06, -0.01, -1.00)      Py = 1470022.93\n\nIz = ( 1.00,  0.00, -0.06)      Pz = 1979333.10\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1977587.12    Lxy = 2056.44       Lxz = 29730.11\n\nLyx = 2056.44       Lyy = 899729.49     Lyz = -3073.94\n\nLzx = 29730.11      Lzy = -3073.94      Lzz = 1471749.05\n</code></pre>"},{"location":"dynamic-information.html#rootwaist","title":"RootWaist","text":"<p>Mass = 2500.00 g</p> <p>Volume = 1359273.48 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00, -1.00,  0.00)      Px = 17354342.61\n\nIy = ( 1.00,  0.00,  0.02)      Py = 38526911.34\n\nIz = (-0.02,  0.00,  1.00)      Pz = 53235490.34\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 38530767.35   Lxy = -134.69       Lxz = 238121.10\n\nLyx = -134.69       Lyy = 17354342.61   Lyz = -0.48\n\nLzx = 238121.10     Lzy = -0.48     Lzz = 53231634.32\n</code></pre>"},{"location":"dynamic-information.html#right-arm","title":"RIGHT ARM","text":""},{"location":"dynamic-information.html#rightfrontalshoulder","title":"RightFrontalShoulder","text":"<p>Mass = 2000.00 g</p> <p>Volume = 516104.81 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.04, -0.99,  0.14)      Px = 2084655.68\n\nIy = ( 0.00, -0.14, -0.99)      Py = 4132399.01\n\nIz = ( 1.00, -0.04,  0.00)      Pz = 4230179.01\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 4226791.05    Lxy = 84382.30      Lxz = -11698.91\n\nLyx = 84382.30      Lyy = 2127281.33    Lyz = -280493.15\n\nLzx = -11698.91     Lzy = -280493.15    Lzz = 4093161.32\n</code></pre>"},{"location":"dynamic-information.html#rightsagittalshoulder","title":"RightSagittalShoulder","text":"<p>Mass = 1000.00 g</p> <p>Volume = 112019.37 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.37,  0.15,  0.91)      Px = 1057898.69\n\nIy = (-0.93,  0.00, -0.38)      Py = 1698826.58\n\nIz = (-0.06, -0.99,  0.14)      Pz = 2215515.46\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1610931.66    Lxy = -69037.90     Lxz = -214886.06\n\nLyx = -69037.90     Lyy = 2187775.81    Lyz = 163005.40\n\nLzx = -214886.06    Lzy = 163005.40     Lzz = 1173533.26\n</code></pre>"},{"location":"dynamic-information.html#rightaxialshoulder","title":"RightAxialShoulder","text":"<p>Mass  = 1000.00 g</p> <p>Volume = 667903.29 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00, -0.01,  1.00)      Px = 611538.52\n\nIy = ( 0.00, -1.00, -0.01)      Py = 6741891.13\n\nIz = ( 1.00,  0.00,  0.00)      Pz = 6925108.26\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 6925108.26    Lxy = 0.00      Lxz = 0.00\n\nLyx = 0.00      Lyy = 6741634.14    Lyz = -39690.86\n\nLzx = 0.00      Lzy = -39690.86     Lzz = 611795.51\n</code></pre>"},{"location":"dynamic-information.html#rightfrontalelbow","title":"RightFrontalElbow","text":"<p>Mass = 1000.00 g</p> <p>Volume = 521543.08 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00,  0.00,  1.00)      Px = 446024.47\n\nIy = (-1.00,  0.00,  0.00)      Py = 2590028.58\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 2623069.51\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 2590028.58    Lxy = 0.00      Lxz = 0.00\n\nLyx = 0.00      Lyy = 2623069.51    Lyz = 0.00\n\nLzx = 0.00      Lzy = 0.00      Lzz = 446024.47\n</code></pre>"},{"location":"dynamic-information.html#rightaxialwrist","title":"RightAxialWrist","text":"<p>Mass = 631.49 g</p> <p>Volume = 40919.54 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.03,  0.04,  1.00)      Px = 326150.78\n\nIy = ( 0.11, -0.99,  0.04)      Py = 612149.05\n\nIz = ( 0.99,  0.11,  0.03)      Pz = 702918.54\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 701463.31     Lxy = -10454.91     Lxz = -10855.70\n\nLyx = -10454.91     Lyy = 612806.24     Lyz = 11471.10\n\nLzx = -10855.70     Lzy = 11471.10      Lzz = 326948.83\n</code></pre>"},{"location":"dynamic-information.html#rightfrontalwrist","title":"RightFrontalWrist","text":"<p>Mass  = 1170.00 g</p> <p>Volume = 759343.98 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.03,  0.00,  1.00)      Px = 880205.15\n\nIy = (-1.00, -0.03,  0.03)      Py = 5332908.02\n\nIz = ( 0.02, -1.00,  0.00)      Pz = 5345304.27\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 5329956.56    Lxy = 101.85        Lxz = 114750.55\n\nLyx = 101.85        Lyy = 5345281.96    Lyz = -8070.00\n\nLzx = 114750.55     Lzy = -8070.00      Lzz = 883178.92\n</code></pre>"},{"location":"dynamic-information.html#left-arm","title":"LEFT ARM","text":""},{"location":"dynamic-information.html#leftfrontalshoulder","title":"LeftFrontalShoulder","text":"<p>Mass = 2000.00 g</p> <p>Volume = 516104.81 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.04, -0.99, -0.14)      Px = 2084628.91\n\nIy = ( 0.00,  0.14, -0.99)      Py = 4132456.63\n\nIz = ( 1.00,  0.04,  0.00)      Pz = 4230264.79\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 4226791.05    Lxy = -85460.30     Lxz = -11670.89\n\nLyx = -85460.30     Lyy = 2127339.64    Lyz = 280493.15\n\nLzx = -11670.89     Lzy = 280493.15     Lzz = 4093219.64\n</code></pre>"},{"location":"dynamic-information.html#leftsagittalshoulder","title":"LeftSagittalShoulder","text":"<p>Mass (user-overridden) = 1000.00 g</p> <p>Volume = 112020.11 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.37, -0.15,  0.91)      Px = 1057896.04\n\nIy = (-0.93,  0.00, -0.38)      Py = 1698815.91\n\nIz = ( 0.06, -0.99, -0.14)      Pz = 2215507.57\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1610920.63    Lxy = 69037.63      Lxz = -214884.85\n\nLyx = 69037.63      Lyy = 2187768.28    Lyz = -163003.88\n\nLzx = -214884.85    Lzy = -163003.88    Lzz = 1173530.62\n</code></pre>"},{"location":"dynamic-information.html#leftaxialshoulder","title":"LeftAxialShoulder","text":"<p>Mass properties of selected components</p> <p>Mass  = 1000.00 g</p> <p>Volume = 667903.29 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00,  0.01,  1.00)      Px = 611538.52\n\nIy = ( 0.00, -1.00,  0.01)      Py = 6741891.13\n\nIz = ( 1.00,  0.00,  0.00)      Pz = 6925108.26\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 6925108.26    Lxy = 0.00      Lxz = 0.00\n\nLyx = 0.00      Lyy = 6741634.14    Lyz = 39690.86\n\nLzx = 0.00      Lzy = 39690.86      Lzz = 611795.51\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalelbow","title":"LeftFrontalElbow","text":"<p>Mass = 1000.00 g</p> <p>Volume = 521543.08 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00,  0.00,  1.00)      Px = 446024.47\n\nIy = (-1.00,  0.00,  0.00)      Py = 2590028.58\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 2623069.51\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 2590028.58    Lxy = 0.00      Lxz = 0.00\n\nLyx = 0.00      Lyy = 2623069.51    Lyz = 0.00\n\nLzx = 0.00      Lzy = 0.00      Lzz = 446024.47\n</code></pre>"},{"location":"dynamic-information.html#leftaxialwrist","title":"LeftAxialWrist","text":"<p>Mass = 631.49 g</p> <p>Volume = 40919.54 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.03,  0.04,  1.00)      Px = 326150.78\n\nIy = ( 0.11, -0.99,  0.04)      Py = 612149.05\n\nIz = ( 0.99,  0.11,  0.03)      Pz = 702918.54\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 701463.31     Lxy = -10454.91     Lxz = -10855.70\n\nLyx = -10454.91     Lyy = 612806.24     Lyz = 11471.10\n\nLzx = -10855.70     Lzy = 11471.10      Lzz = 326948.83\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalwrist","title":"LeftFrontalWrist","text":"<p>Mass = 1170.00 g</p> <p>Volume = 759343.98 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.02,  0.00,  1.00)      Px = 880205.15\n\nIy = (-1.00, -0.03,  0.02)      Py = 5332908.02\n\nIz = ( 0.02, -1.00,  0.00)      Pz = 5345304.27\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 5330646.84    Lxy = 127.73        Lxz = 100487.37\n\nLyx = 127.73        Lyy = 5345281.96    Lyz = -8069.63\n\nLzx = 100487.37     Lzy = -8069.63      Lzz = 882488.65\n</code></pre>"},{"location":"dynamic-information.html#right-leg","title":"RIGHT LEG","text":""},{"location":"dynamic-information.html#rightaxialhip","title":"RightAxialHip","text":"<p>Mass = 849.45 g</p> <p>Volume = 185143.45 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 1.00,  0.00,  0.02)      Px = 1564158.65\n\nIy = (-0.02,  0.00,  1.00)      Py = 1706392.72\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 2645088.53\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1564202.47    Lxy = 0.00      Lxz = 2496.11\n\nLyx = 0.00      Lyy = 2645088.53    Lyz = 0.00\n\nLzx = 2496.11       Lzy = 0.00      Lzz = 1706348.90\n</code></pre>"},{"location":"dynamic-information.html#rightsagittalhip","title":"RightSagittalHip","text":"<p>Mass = 1454.59 g</p> <p>Volume = 357656.76 mm\u00b3 Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.01, -1.00,  0.00)      Px = 1191564.94\n\nIy = ( 1.00,  0.01,  0.00)      Py = 1545840.34\n\nIz = ( 0.00,  0.00,  1.00)      Pz = 2270481.60\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1545815.41    Lxy = -2971.75      Lxz = -4.07\n\nLyx = -2971.75      Lyy = 1191589.87    Lyz = 9.16\n\nLzx = -4.07     Lzy = 9.16      Lzz = 2270481.60\n</code></pre>"},{"location":"dynamic-information.html#rightfrontalhip","title":"RightFrontalHip","text":"<p>Mass = 1891.52 g</p> <p>Volume = 5587643.87 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.06,  0.00,  1.00)      Px = 7447846.66\n\nIy = (-1.00,  0.00, -0.06)      Py = 15103348.97\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 15112043.87\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 15077735.36   Lxy = 0.00      Lxz = -442073.53\n\nLyx = 0.00      Lyy = 15112043.87   Lyz = 0.00\n\nLzx = -442073.53    Lzy = 0.00      Lzz = 7473460.27\n</code></pre>"},{"location":"dynamic-information.html#rightfrontalknee","title":"RightFrontalKnee","text":"<p>Mass = 1948.24 g</p> <p>Volume = 4141636.01 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00,  0.00,  1.00)      Px = 3843635.20\n\nIy = ( 0.00, -1.00,  0.00)      Py = 21411108.92\n\nIz = ( 1.00,  0.00,  0.00)      Pz = 21861710.56\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 21861710.01   Lxy = 0.00      Lxz = 3157.06\n\nLyx = 0.00      Lyy = 21411108.92   Lyz = 0.00\n\nLzx = 3157.06       Lzy = 0.00      Lzz = 3843635.76\n</code></pre>"},{"location":"dynamic-information.html#rightfrontalankle","title":"RightFrontalAnkle","text":"<p>Mass = 1503.59 g</p> <p>Volume = 364314.92 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 1.00,  0.04,  0.00)      Px = 1395246.39\n\nIy = (-0.04,  1.00,  0.00)      Py = 1589600.30\n\nIz = ( 0.00,  0.00,  1.00)      Pz = 2418656.52\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1395488.46    Lxy = 6854.86       Lxz = 0.01\n\nLyx = 6854.86       Lyy = 1589358.23    Lyz = 0.00\n\nLzx = 0.01      Lzy = 0.00      Lzz = 2418656.52\n</code></pre>"},{"location":"dynamic-information.html#rightsagittalankle","title":"RightSagittalAnkle","text":"<p>Mass = 3133.40 g</p> <p>Volume = 836243.07 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.96,  0.06, -0.29)      Px = 7156686.84\n\nIy = ( 0.29, -0.01,  0.96)      Py = 13916875.64\n\nIz = ( 0.06, -1.00, -0.03)      Pz = 14811538.03\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 7742029.63    Lxy = 455866.32     Lxz = -1851656.76\n\nLyx = 455866.32     Lyy = 14781323.09   Lyz = -147512.99\n\nLzx = -1851656.76   Lzy = -147512.99    Lzz = 13361747.79\n</code></pre>"},{"location":"dynamic-information.html#left-leg","title":"LEFT LEG","text":""},{"location":"dynamic-information.html#leftaxialhip","title":"LeftAxialHip","text":"<p>Mass = 849.45 g</p> <p>Volume = 185143.45 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 1.00,  0.00,  0.02)      Px = 1564158.65\n\nIy = (-0.02,  0.00,  1.00)      Py = 1706392.72\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 2645088.53\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1564202.47    Lxy = 0.00      Lxz = 2496.11\n\nLyx = 0.00      Lyy = 2645088.53    Lyz = 0.00\n\nLzx = 2496.11       Lzy = 0.00      Lzz = 1706348.90\n</code></pre>"},{"location":"dynamic-information.html#leftsagittalhip","title":"LeftSagittalHip","text":"<p>Mass = 1454.59 g</p> <p>Volume = 357656.76 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.01, -1.00,  0.00)      Px = 1191564.94\n\nIy = ( 1.00,  0.01,  0.00)      Py = 1545840.34\n\nIz = ( 0.00,  0.00,  1.00)      Pz = 2270481.60\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1545815.41    Lxy = -2971.75      Lxz = -4.07\n\nLyx = -2971.75      Lyy = 1191589.87    Lyz = 9.16\n\nLzx = -4.07     Lzy = 9.16      Lzz = 2270481.60\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalhip","title":"LeftFrontalHip","text":"<p>Mass = 1891.52 g</p> <p>Volume = 5587643.87 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = (-0.06,  0.00,  1.00)      Px = 7447846.66\n\nIy = (-1.00,  0.00, -0.06)      Py = 15103348.97\n\nIz = ( 0.00, -1.00,  0.00)      Pz = 15112043.87\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 15077735.36   Lxy = 0.00      Lxz = -442073.53\n\nLyx = 0.00      Lyy = 15112043.87   Lyz = 0.00\n\nLzx = -442073.53    Lzy = 0.00      Lzz = 7473460.27\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalknee","title":"LeftFrontalKnee","text":"<p>Mass = 1948.24 g</p> <p>Volume = 4141636.01 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.00,  0.00,  1.00)      Px = 3843635.20\n\nIy = ( 0.00, -1.00,  0.00)      Py = 21411108.92\n\nIz = ( 1.00,  0.00,  0.00)      Pz = 21861710.56\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 21861710.01   Lxy = 0.00      Lxz = 3157.06\n\nLyx = 0.00      Lyy = 21411108.92   Lyz = 0.00\n\nLzx = 3157.06       Lzy = 0.00      Lzz = 3843635.76\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalankle","title":"LeftFrontalAnkle","text":"<p>Mass = 1503.59 g</p> <p>Volume = 364099.32 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 1.00, -0.06,  0.00)      Px = 1391550.41\n\nIy = ( 0.06,  1.00,  0.00)      Py = 1590780.84\n\nIz = ( 0.00,  0.00,  1.00)      Pz = 2416060.36\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 1392286.60    Lxy = -12088.37     Lxz = 0.01\n\nLyx = -12088.37     Lyy = 1590044.65    Lyz = 0.01\n\nLzx = 0.01      Lzy = 0.01      Lzz = 2416060.36\n</code></pre>"},{"location":"dynamic-information.html#leftfrontalankle_1","title":"LeftFrontalAnkle","text":"<p>Mass = 3133.40 g</p> <p>Volume = 828418.18 mm\u00b3</p> <p>Principal axes of inertia and principal moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass.</p> <pre><code>Ix = ( 0.97, -0.08, -0.24)      Px = 7368906.11\n\nIy = ( 0.24,  0.04,  0.97)      Py = 13515459.01\n\nIz = (-0.06, -1.00,  0.06)      Pz = 14635257.08\n</code></pre> <p>Moments of inertia: ( g *  mm\u00b2 ) Taken at the center of mass and aligned with the output coordinate system.</p> <pre><code>Lxx = 7763728.47    Lxy = -524257.51    Lxz = -1424772.26\n\nLyx = -524257.51    Lyy = 14591640.60   Lyz = 173925.09\n\nLzx = -1424772.26   Lzy = 173925.09     Lzz = 13164253.12\n</code></pre>"},{"location":"introduction.html","title":"Introduction","text":""},{"location":"introduction.html#introduction","title":"Introduction","text":""},{"location":"introduction.html#welcome","title":"Welcome","text":"<p>Welcome to TEO!</p>"},{"location":"introduction.html#sites","title":"Sites","text":"<ul> <li>http://roboticslab.uc3m.es/roboticslab/robot/teo-humanoid</li> <li>https://robots.uc3m.es/robot-household-companion-web/</li> </ul>"},{"location":"introduction.html#everyday-log","title":"Everyday Log","text":"<ul> <li>Motor/Driver Procedure</li> </ul>"},{"location":"introduction.html#links-of-general-interest","title":"Links of General Interest","text":"<ul> <li>TEO DIAGRAMAS</li> <li>TEO Cluster: Network, IP, MAC and PC specification list\u00a0/\u00a0TEO Network troubleshooting</li> <li>Hoja de RESERVAS de partes de robot</li> <li>Demo Procedure\u00a0/\u00a0What to Take to Demos</li> </ul>"},{"location":"introduction.html#repositories","title":"Repositories","text":"<ul> <li>For relevant parts of the\u00a0roboticslab-uc3m organization at GitHub, refer to:</li> <li>TEO developer manual</li> <li>TEOrepo: Private repository containing HW, backups, etc</li> <li>Source code (TEOrepo)</li> <li>Backups:\u00a0https://apps-robots.uc3m.es/svn/TEOrepo/backups\u00a0(How to restore a booteable image partition:\u00a0spanish)</li> <li>[DEPRECATED]\u00a0Link to the Old Repository RH2repo (old SVN)\u00a0(SVN Tutorial:\u00a0spanish)</li> </ul>"},{"location":"introduction.html#social-media","title":"Social media","text":"<ul> <li>Videos:\u00a0jgvictores channel santimorante channel</li> <li>https://www.youtube.com/playlist?list=PLhVfUTRQ_sD7A_Bt8ew1qv_8cUsDruwHF</li> </ul>"},{"location":"introduction.html#more","title":"More","text":"<p>Still lots of material on the wiki!</p> <p>We'll be porting material and updating little by little!</p>"},{"location":"network-information.html","title":"Network Information","text":""},{"location":"network-information.html#network-information","title":"Network Information","text":""},{"location":"network-information.html#teonet-main-router","title":"TEONET (main router)","text":"<ul> <li>wifi-ssid: TEONET</li> <li> <p>wifi-password: teochallenge</p> </li> <li> <p>External IP: 163.117.150.74</p> </li> <li>Internal IP: 2.2.2.1</li> <li>IP Subnet Mask: 255.255.255.0</li> <li>Gateway IP Address: 163.117.150.2</li> <li>Primary DNS: 163.117.131.35</li> <li>Configuration web: www.routerlogin.net</li> <li>user: admin</li> <li>pass: admin</li> </ul>"},{"location":"network-information.html#tl-wr2543nd-router-configured-as-switch","title":"TL-WR2543ND: router configured as switch","text":"<ul> <li>External IP: Dynamic IP</li> <li>Internal IP: 2.2.2.2</li> <li>IP Subnet Mask: 255.255.255.0</li> <li>user: admin</li> <li>pass: admin</li> </ul>"},{"location":"network-information.html#ubiquiti-edgerouter-x-teo-internal-router-as-a-switch","title":"Ubiquiti EdgeRouter X: Teo internal router as a switch","text":"<ul> <li>Internal IP: 2.2.2.10</li> <li>IP Subnet Mask: 255.255.255.0</li> <li>user: ubnt</li> <li>pass: ubnt</li> </ul>"},{"location":"network-information.html#manipulation-left-robot-pc","title":"manipulation (left robot PC)","text":"<p>Memory 16 GiB, Processor Intel(R) Core(TM) i7-10710U CPU @ 1.10GHz, Disk 111 GiB.</p> <ul> <li>OS (dual boot):</li> <li>Partition 80Gb: Ubuntu 20.04 Focal Fossa</li> <li>Partition 20Gb: Ubuntu 16.04 Xenial</li> </ul>"},{"location":"network-information.html#manipulation-pass","title":"manipulation: pass","text":"<ul> <li>teo / teo</li> <li>su: manipulation</li> </ul>"},{"location":"network-information.html#manipulation-macip","title":"manipulation: MAC/IP","text":"<ul> <li>wlan1\u00a0\u00a05c:d9:98:9a:94:5c\u00a0\u00a02.2.2.51</li> <li>eth0\u00a0\u00a000:18:7d:0b:2d:9d\u00a0\u00a02.2.2.61</li> </ul>"},{"location":"network-information.html#manipulation-init","title":"manipulation: init","text":"<p>Runs <code>yarp server</code> as service using daemontools), activated in <code>/etc/service/yarpserver/run</code> with <code>chmod +x</code> through the lines:</p> <pre><code>#!/bin/bash\nexport PATH=/usr/local/bin:/usr/bin:/bin\nexport YARP_CONFIG_HOME=/home/teo/.config/yarp\nyarp server --read\n</code></pre> <p>Also, runs <code>yarprun --server /manipulation</code> as service using daemontools, activated in <code>/etc/service/yarprun/run</code> with <code>chmod +x</code> through the lines:</p> <pre><code>#!/bin/bash\nexport ATH=/usr/local/bin:/usr/bin:/bin\nexport YARP_CONFIG_HOME=/home/teo/.config/yarp\nyarprun --server\u00a0/manipulation\n</code></pre>"},{"location":"network-information.html#manipulation-install","title":"manipulation: install","text":"<ul> <li>GCC 7.5</li> <li>yarp-devices</li> <li>kinematics-dynamics</li> <li>PCAN-M2</li> <li>JR3</li> <li>CuiAbsolute:</li> <li>VirtualBox Image with Windows 7 and MPLAB IDE v8.92</li> <li><code>YARP_ROBOT_NAME=teo</code></li> <li><code>YARP_PORT_PREFIX=/teo</code></li> <li><code>YARP_COLORED_OUTPUT=1</code></li> </ul>"},{"location":"network-information.html#locomotion-right-robot-pc","title":"locomotion (right robot PC)","text":"<p>Memory 16 GiB, Processor Intel(R) Core(TM) i5-7300U CPU @ 2.60GHz, GPU: HD Graphics 620, Disk 106 GiB.</p> <ul> <li>OS (dual boot):</li> <li>Partition 80Gb: Ubuntu 20.04 Focal Fossa</li> <li>Partition 20Gb: Ubuntu 16.04 Xenial</li> </ul>"},{"location":"network-information.html#locomotion-pass","title":"locomotion: pass","text":"<ul> <li>teo / teo</li> <li>su: locomotion</li> </ul>"},{"location":"network-information.html#locomotion-macip","title":"locomotion: MAC/IP","text":"<ul> <li>wlan1\u00a0\u00a05c:d9:98:9a:94:5d\u00a0\u00a02.2.2.52</li> <li>eth0\u00a0\u00a000:18:7d:0b:2d:71\u00a0\u00a02.2.2.62</li> </ul>"},{"location":"network-information.html#locomotion-init","title":"locomotion: init","text":"<p>The execution of <code>yarprun --server /locomotion</code> is implemented as service using daemontools, activated in <code>/etc/service/yarprun/run</code> with <code>chmod +x</code> through the lines:</p> <pre><code>#!/bin/bash \u00a0\nexport PATH=/usr/local/bin:/usr/bin:/bin\nexport YARP_CONFIG_HOME=/home/teo/.config/yarp\nyarprun --server /locomotion\n</code></pre>"},{"location":"network-information.html#locomotion-install","title":"locomotion: install","text":"<ul> <li>GCC 7.5</li> <li>yarp-devices</li> <li>kinematics-dynamics</li> <li>XSENS</li> <li>CuiAbsolute:</li> <li>VirtualBox Image with Windows 7: MPLAB IDE v8.92 and EasySetUp</li> <li><code>YARP_ROBOT_NAME=teo</code></li> <li><code>YARP_PORT_PREFIX=/teo</code></li> <li><code>YARP_COLORED_OUTPUT=1</code></li> </ul>"},{"location":"network-information.html#teo-head-center-robot-pc","title":"teo-head (center robot PC)","text":"<p>Memory 16 GiB, Processor Intel(R) Core(TM) i5-7300U CPU @ 2.60GHz, GPU: HD Graphics 620, Disk 52 GiB. - OS (dual boot):   - Partition 40Gb: Ubuntu 20.04 Focal Fossa   - Partition 20Gb: Ubuntu 16.04 Xenial</p>"},{"location":"network-information.html#teo-head-pass","title":"teo-head: pass","text":"<ul> <li>user: teo</li> <li>pass: teo</li> </ul>"},{"location":"network-information.html#teo-head-macip","title":"teo-head: MAC/IP","text":"<ul> <li>eth1\u00a0\u00a000:01:2e:51:9c:c1\u00a0\u00a02.2.2.53</li> </ul>"},{"location":"network-information.html#teo-head-init","title":"teo-head: init","text":"<p>The execution of <code>yarprun --server /head</code> is implemented as service using daemontools, activated in <code>/etc/service/yarprun/run</code> with <code>chmod +x</code> through the lines:</p> <pre><code>#!/bin/bash\nexport PATH=/usr/local/bin:/usr/bin:/bin\nexport YARP_CONFIG_HOME=/home/teo/.config/yarp\nyarprun --server /head\n</code></pre>"},{"location":"network-information.html#teo-head-install","title":"teo-head: install","text":"<ul> <li>GCC 7.5</li> <li>vision</li> <li>speech</li> <li><code>YARP_COLORED_OUTPUT=1</code></li> </ul>"},{"location":"network-information.html#mapping-hostnames-to-ip-addresses-in-your-computer","title":"Mapping hostnames to IP addresses in your computer","text":"<p>You can edit the <code>/etc/hosts</code> file of your system for mapping some hostnames to IP addresses. Now, you can associate the name of teo pc's with their IPs:</p> <pre><code>2.2.2.51 manipulation\n2.2.2.52 locomotion\n2.2.2.53 head\n</code></pre> <p>For example, if you want connect by ssh with teo-manipulation PC, you can put <code>ssh manipulation</code> instead of <code>ssh 2.2.2.51</code>. It's easier to remember!!</p>"},{"location":"network-information.html#other-hardware-configuration","title":"Other hardware configuration","text":"<ul> <li>Setting up Wifi connection: Netgear A6100 WiFi USB Mini Adapter</li> </ul>"},{"location":"network-information.html#uncategorized","title":"Uncategorized","text":"<pre><code>sudo mount -t nfs 163.117.150.231:/home/teo sitio\\_de\\_montaje\nrsync -avzP local/dir/ teo@2.2.2.51:remote/dir/\n</code></pre>"},{"location":"switches-and-power.html","title":"Switches and Power","text":""},{"location":"switches-and-power.html#switches-and-power","title":"Switches and Power","text":"Main Switches Instructions  First, turn on the two main power supplies of TEO (yellow circles) and adjust the voltage to 42 V (red arrows).  Turn on the General switch and then turn on the switches corresponding to the label marked on the top of each one.  Finally, turn on each of the switches corresponding to the computers. The buttons of the second column are responsible for turning on the computers of the head, manipulation and locomotion in this order. The buttons of the first column are used to reset the computers in the same order as the second column.   The emergency buttons will allow us to stop the electricity of motors and drivers of each part of the robot, documented under each button with a label:  head, arms, legs"},{"location":"tables.html","title":"Tables","text":""},{"location":"tables.html#tables","title":"Tables","text":""},{"location":"tables.html#joint-limits","title":"Joint Limits","text":"<p>Can be found at Motores: motores</p>"},{"location":"tables.html#dh-parameters","title":"DH Parameters","text":""},{"location":"tables.html#group-head","title":"Group: head","text":""},{"location":"tables.html#trunk-for-head-root-to-neck","title":"trunk for head (root to neck)","text":"<p>dh-root-head.csv</p> Link \u03b8 D A \u03b1 1 q13 l0 0 -90 2 q14 0 0 90"},{"location":"tables.html#head","title":"head","text":"<p>dh-head.csv</p> Link \u03b8 D A \u03b1 1 q27 l1+l2 0 -90 2 q28 0 0 90"},{"location":"tables.html#head-additional-transformations","title":"head additional transformations","text":"<p>dh-head-transformations.csv</p> Name Transformation H_head_rgb TrasZ(l3) * RotZ(-90) * RotX(-90) * TrasX(-l14) H_head_depth TrasZ(l3) * RotZ(-90) * RotX(-90) * TrasX(-l14-l15) H_head_flea TrasZ(l3+l4) * RotZ(-90) * RotX(-90)"},{"location":"tables.html#group-rightarm","title":"Group: rightArm","text":""},{"location":"tables.html#trunk-for-rightarm-root-to-rightarm","title":"trunk for rightArm (root to rightArm)","text":"<p>dh-root-rightArm.csv</p> Link \u03b8 D A \u03b1 1 q13 l0 0 -90 2 -90+q14 -l5 l1 0"},{"location":"tables.html#rightarm","title":"rightArm","text":"<p>dh-rightArm.csv</p> Link \u03b8 D A \u03b1 1 q15 0 0 -90 2 -90+q16 0 0 -90 3 -90+q17 -l6 0 -90 4 q18 0 0 90 5 q19 -l7 0 -90 6 -90+q20 0 -l8 0"},{"location":"tables.html#fetch-right","title":"fetch (right)","text":"<p>dh-fetch.csv</p> Link \u03b8 D A \u03b1 1 -90 0 0 90 2 0 lf 0 0"},{"location":"tables.html#group-leftarm","title":"Group: leftArm","text":""},{"location":"tables.html#trunk-for-leftarm-root-to-leftarm","title":"trunk for leftArm (root to leftArm)","text":"<p>dh-root-leftArm.csv</p> Link \u03b8 D A \u03b1 1 q13 l0 0 -90 2 -90+q14 l5 l1 0"},{"location":"tables.html#leftarm","title":"leftArm","text":"<p>dh-leftArm.csv</p> Link \u03b8 D A \u03b1 1 q21 0 0 -90 2 -90+q22 0 0 -90 3 -90+q23 -l6 0 -90 4 q24 0 0 90 5 q25 -l7 0 -90 6 -90+q26 0 -l8 0"},{"location":"tables.html#fetch-left","title":"fetch (left)","text":"<p>dh-fetch.csv</p> Link \u03b8 D A \u03b1 1 -90 0 0 90 2 0 lf 0 0"},{"location":"tables.html#group-rightleg","title":"Group: rightLeg","text":""},{"location":"tables.html#root-to-rightleg","title":"root to rightLeg","text":"<p>dh-root-rightLeg.csv</p> Link \u03b8 D A \u03b1 1 90 -l9 -l13 0"},{"location":"tables.html#rightleg","title":"rightLeg","text":"<p>dh-rightLeg.csv</p> Link \u03b8 D A \u03b1 1 q6 0 0 90 2 90+q5 0 0 90 3 q4 0 -l10 0 4 q3 l16 -l11 0 5 q2 0 0 -90 6 q1 0 -l12 0"},{"location":"tables.html#group-leftleg","title":"Group: leftLeg","text":""},{"location":"tables.html#root-to-leftleg","title":"root to leftLeg","text":"<p>dh-root-leftLeg.csv</p> Link \u03b8 D A \u03b1 1 90 -l9 l13 0"},{"location":"tables.html#leftleg","title":"leftLeg","text":"<p>dh-leftLeg.csv</p> Link \u03b8 D A \u03b1 1 q7 0 0 90 2 90+q8 0 0 90 3 q9 0 -l10 0 4 q10 -l16 -l11 0 5 q11 0 0 -90 6 q12 0 -l12 0"},{"location":"tables.html#group-deprecated-transformations","title":"Group: Deprecated transformations","text":"<p>The below are not required at time of writing, and may become outdated with time.</p>"},{"location":"tables.html#deprecated-trunk-root-to-hip","title":"Deprecated trunk (root to hip)","text":"<p>This is the original <code>trunk</code>, but the three variants (for <code>head</code>, <code>rightArm</code>, <code>leftArm</code>; respectively, above) seem to be more useful.</p> <p>deprecated/dh-trunk.csv</p> Link \u03b8 D A \u03b1 1 q13 l0 0 -90 2 q14 0 0 0"},{"location":"tables.html#deprecated-additional-transformations","title":"Deprecated additional transformations","text":"<p>Some not required, redundant or may be derived from from existing <code>dh-root-*.csv</code> contents (above).</p> <p>deprecated/dh-transformations.csv</p> Name Transformation H_hip_neck RotX(90) H_hip_leftArm TrasZ(l5) * RotZ(-90) * TrasX(l1) H_hip_rightArm TrasZ(-l5) * RotZ(-90) * TrasX(l1)"},{"location":"tables.html#link-lengths","title":"Link Lengths","text":"<p>lengths.csv</p> lengths distance [mm] l0 193.2 l1 305 l2 162.5 l3 59.742 l4 37.508 l5 346.92 l6 329.01 l7 215 l8 90 l9 92 l10 330 l11 300 l12 123.005 l13 146 l14 18 l15 26 l16 17.5 lf 97.5"},{"location":"tables.html#bill-of-materials-bom","title":"Bill of materials (BOM)","text":"<p>bom.csv</p> Device Brand Model YARP device Desciption/Comments EC Motor Maxon 339282/339287/400108/402686/411815 nan 30/50/70 W Motor Driver Technosoft iPOS 3602/3604/4808 (MX) TechnosoftIpos 3602 -&gt; front wrist 3604 -&gt; all except legs and trunk 4808 -&gt; legs and trunk Relative Encoder CUI Inc AMT 203-V TechnosoftIpos nan Absolute Encoder CUI Inc AMT 203-V CuiAbsolute Uses PIC18F2580 Force-Torque Sensor JR3 50M31A3-125-DH Jr3 50M31A3-125-DH -&gt; wrist ((( unknown ))) -&gt; ankle Inertial Sensor XSENS MTi-28A53G35 xsensmtx Product ID: MTi-28A53G35 Device ID: 00305355 RGBD Sensor ASUS XtionPRO Live OpenNI2Server RGB and Depth Sensor RGB Camera Point Grey Flea3 FL3-U3-88S2C-C AravisGigE USB3 Fetch Hand Lacquey Fetch Hand LacqueyFetch Three finger underactuated CAN board PEAK-System PCAN-M.2 CanBusPeak Four channels"},{"location":"tables.html#motores","title":"Motores","text":"<ul> <li>Original with formulas: editable/motores.ods</li> </ul>"},{"location":"tables.html#motores-motores","title":"Motores: motores","text":"<p>motores-motores.csv</p> Joint Label CAN Bus CAN ID YARP Port YARP ID MOTOR R. total Hard. Limit Min (degrees) Hard. Limit Max (degrees) Soft. Limit Min (degrees) Soft. Limit Max (degrees) Human-inspired Min Limit (degrees) Human-inspired Max Limit (degrees) SagittalRightAnkle SRA1 Locomotion /dev/can0 1 /teo/rightLeg 5 402686 235.2 -24.9561 47.522 -19.9 42.5 -5 5 FrontalRightAnkle FRA2 Locomotion /dev/can0 2 /teo/rightLeg 4 411815 270.4 -28.1195 30.3867 -23.1 25.4 -20 25.4 FrontalRightKnee FRK3 Locomotion /dev/can0 3 /teo/rightLeg 3 402686 235.2 -66.3269 87.4341 -61.3 82.4 0 82.4 FrontalRightHip FRH4 Locomotion /dev/can0 4 /teo/rightLeg 2 402686 192 -36.6257 47.2759 -31.6 42.3 -31.6 30 SagittalRightHip SRH5 Locomotion /dev/can0 5 /teo/rightLeg 1 402686 523.2 -19.2443 17.4868 -14.2 12.5 -14.2 12.5 AxialRightHip ARH6 Locomotion /dev/can0 6 /teo/rightLeg 0 339287 400 -37.7856 32.935 -32.8 27.9 -32.8 27.9 FrontalTrunk FT14 Locomotion /dev/can0 14 /teo/trunk 1 339287 480 -95.413 15.1142 -90.4 10.1 -90.4 10.1 AxialTrunk AT13 Locomotion /dev/can1 13 /teo/trunk 0 411815 160 -51.3181 51.3181 -59.3 46.3 -30 30 AxialLeftHip ALH7 Locomotion /dev/can1 7 /teo/leftLeg 0 339287 400 -32.935 37.7856 -27.9 32.8 -27.9 32.8 SagittalLeftHip SLH8 Locomotion /dev/can1 8 /teo/leftLeg 1 402686 523.2 -17.4868 19.2443 -12.5 14.2 -12.5 14.2 FrontalLeftHip FLH9 Locomotion /dev/can1 9 /teo/leftLeg 2 411815 192 -36.6257 47.2759 -31.6 42.3 -31.6 30 FrontalLeftKnee FLK10 Locomotion /dev/can1 10 /teo/leftLeg 3 402686 235.2 -66.3269 87.4341 -61.3 82.4 0 82.4 FrontalLeftAnkle FLA11 Locomotion /dev/can1 11 /teo/leftLeg 4 402686 270.4 -28.1195 30.3867 -23.1 25.4 -20 25.4 SagittalLeftAnkle SLA12 Locomotion /dev/can1 12 /teo/leftLeg 5 402686 235.2 -47.522 24.9561 -42.5 19.9 -5 5 FrontalRightShoulder FRS15 Manipulation /dev/can2 15 /teo/rightArm 0 411815 160 -103.076 110.967 -98.1 106 -98.1 45 SagittalRightShoulder SRS16 Manipulation /dev/can2 16 /teo/rightArm 1 411815 160 -80.4745 27.4165 -75.5 22.4 -75.5 22.4 AxialRightShoulder ARS17 Manipulation /dev/can2 17 /teo/rightArm 2 608141 120 -85.1494 62.0211 -80.1 57 -40 55 FrontalRightElbow FRE18 Manipulation /dev/can2 18 /teo/rightArm 3 411815 160 -104.569 103.409 -99.6 98.4 -99.6 5 AxialRightWrist ARW19 Manipulation /dev/can2 19 /teo/rightArm 4 400108 120 -85.413 104.64 -80.4 99.6 -80.4 90 FrontalRightWrist FRW20 Manipulation /dev/can2 20 /teo/rightArm 5 339282 120 -120.123 49.7188 -115.1 44.7 -70 44.7 FrontalNeck FN28 Manipulation /dev/can2 28 /teo/head 1 nan nan nan nan -10 10 nan nan AxialNeck AN27 Manipulation /dev/can3 27 /teo/head 0 nan nan nan nan -60 60 nan nan FrontalLeftShoulder FLS21 Manipulation /dev/can3 21 /teo/leftArm 0 411815 160 -101.828 118.19 -96.8 113.2 -96.8 45 SagittalLeftShoulder SLS22 Manipulation /dev/can3 22 /teo/leftArm 1 411815 160 -28.8928 81.4587 -23.9 76.5 -23.9 76.5 AxialLeftShoulder ALS23 Manipulation /dev/can3 23 /teo/leftArm 2 400108 120 -56.5905 89.0861 -51.6 84.1 -51.6 40 FrontalLeftElbow FLE24 Manipulation /dev/can3 24 /teo/leftArm 3 339282 160 -106.134 101.845 -101.1 96.8 -101.1 5 AxialLeftWrist ALW25 Manipulation /dev/can3 25 /teo/leftArm 4 339282 120 -106.327 81.4411 -101.3 76.4 -90 76.4 FrontalLeftWrist FLW26 Manipulation /dev/can3 26 /teo/leftArm 5 339282 120 -118.26 66.3445 -113.3 61.3 -70 61.3"},{"location":"tables.html#motores-protecciones-brazos","title":"Motores: protecciones-brazos","text":"<p>motores-protecciones-brazos.csv</p> Unnamed: 0 Unnamed: 1 Hombro Frontal Hombro Sagital Hombro Axial Codo Frontal Mu\u00f1eca Axial Mu\u00f1eca Frontal nan nan nan nan nan nan nan nan Ref Motor nan 339282 339282 339282 339282 339282 339282 driver nan iPOS3604 iPOS3604 iPOS3604 iPOS3604 iPOS3602 iPOS3604 nan nan nan nan nan nan nan nan Corriente Nominal (A) Inom 0.849 0.849 0.849 0.849 0.849 0.849 Temperatura Max del bobinado (\u00baC) Tmax 125 125 125 125 125 125 Temperatura final del bobinado (\u00baC) Tw,\u221e 100 100 80 100 80 100 Corriente Max de trabajo (A) Ipeak 5.38 5.38 5.38 5.38 3.20 5.38 Resistencia termica bobinado (K/W) Rth1 3.96 3.96 3.96 3.96 3.96 3.96 Resistencia termica carcasa (K/W) Rth2 5.70 5.70 5.70 5.70 5.70 5.70 Constante de tiempo termica (s) \u03c4w 18.25 18.25 18.25 18.25 18.25 18.25 Coeficiente de resistencia Cu (K-1) \u03b1CU 0.0039 0.0039 0.0039 0.0039 0.0039 0.0039 Resistencia del motor (\u2126) Rmot 6.69 6.69 6.69 6.69 6.69 6.69 PROTECCION DE CORRIENTES DE PICO nan nan nan nan nan nan nan Factor de sobrecarga K 8.1145 8.1145 6.0482 8.1145 3.5975 8.1145 Tiempo de Corte de sobrecarga (s) ton 0.2793 0.2793 0.5059 0.2793 1.4679 0.2793 PROTECCION DE CORRIENTES DE i2t nan nan nan nan nan nan nan Perdidas por efecto Joule (W) PJ 7.7640 7.7640 5.6936 7.7640 5.6936 7.7640 Resistencia del bobinado a Tw,\u221e(\u2126) RTW 8.6468 8.6468 8.1250 8.6468 8.1250 8.6468 Corriente I2t (A) II2t 0.9476 0.9476 0.8371 0.9476 0.8371 0.9476 Tiempo de Corte de I2t (s) t 25.3053 25.3053 14.5759 25.3053 14.5759 25.3053 nan nan nan nan nan nan nan nan Motor Tensi\u00f3n (V) Peso (Gr) Par max (Nm) Par RMS (Nm) I max (A) I RMS (A) Vel. Nom (rpm) Flat Brushless EC 45 30W (339282) 36 110 0.337 0.0666 5.38 0.849 4760 Driver nan nan nan nan nan nan nan iPOS3604MX-CAN 36 ,,, ,,, ,,, 10 (2,5s) 4 ,,,"},{"location":"tables.html#motores-protecciones-piernas","title":"Motores: protecciones-piernas","text":"<p>motores-protecciones-piernas.csv</p> Unnamed: 0 Unnamed: 1 Tobillo Sagital Tobillo Frontal Rodilla Cadera Frontal Cadera Sagital Cadera Axial Torques RMS Articulaci\u00f3n (Nm) nan 18.71 25.15 26.72 10.22 53.39 3.20 Torques Max Articulaci\u00f3n (Nm) nan 49.70 59.43 61.86 25.99 84.41 7.24 nan nan nan nan nan nan nan nan Relaci\u00f3n de Red. Poleas nan 1.47 1.69 1.47 1.2 3.27 2.5 Torques Constant (mNm/A) nan 33.5 53.3 53.3 53.3 101 101 nan nan nan nan nan nan nan nan Torques RMS Motor (Nm) nan 0.0796 0.0930 0.1136 0.0533 0.1020 0.0080 Torques Max Motor (Nm) nan 0.2113 0.2198 0.2630 0.1354 0.1613 0.0181 nan nan nan nan nan nan nan nan Velocidad Eje Max nan 24.9040 8.1382 32.9043 30.1766 4.2060 0.0000 Velocidad Motor Max nan 5857.4200 2200.5700 7739.1000 5793.9000 2200.5700 0.0000 nan nan nan nan nan nan nan nan Currents RMS Motor (A) nan 2.3748 1.7451 2.1317 0.9991 1.0104 0.0793 Currents Max Motor (A) nan 6.3078 4.1235 4.9344 2.5402 1.5974 0.1792 nan nan nan nan nan nan nan nan Ref Motor nan 251601 402686 402686 402686 339287 339287 driver nan iPOS3604 iPOS3604 iPOS3604 iPOS3604 iPOS3602 iPOS3604 nan nan nan nan nan nan nan nan Corriente Nominal (A) Inom 2.360 1.930 1.930 1.930 0.861 0.861 Temperatura Max del bobinado (\u00baC) Tmax 125 125 125 125 125 125 Temperatura final del bobinado (\u00baC) Tw,\u221e 100 100 100 100 100 100 Corriente Max de trabajo (A) Ipeak 20.00 20.00 20.00 20.00 4.86 4.86 Resistencia termica bobinado (K/W) Rth1 4.50 4.22 4.22 4.22 4.50 4.50 Resistencia termica carcasa (K/W) Rth2 4.25 3.25 3.25 3.25 4.25 4.25 Constante de tiempo termica (s) \u03c4w 26.35 48.25 48.25 48.25 26.35 26.35 Coeficiente de resistencia Cu (K-1) \u03b1CU 0.0039 0.0039 0.0039 0.0039 0.0039 0.0039 Resistencia del motor (\u2126) Rmot 0.978 1.74 1.74 1.74 7.41 7.41 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan PROTECCION DE CORRIENTES DE PICO nan nan nan nan nan nan nan Factor de sobrecarga K 12.1549 15.5775 15.5775 15.5775 8.0959 8.0959 Tiempo de Corte de sobrecarga (s) ton 0.1790 0.1993 0.1993 0.1993 0.4051 0.4051 Corriente Max de trabajo (A) Ipeak 20.00 20.00 20.00 20.00 4.86 4.86 PROTECCION DE CORRIENTES DE i2t nan nan nan nan nan nan nan Perdidas por efecto Joule (W) PJ 8.5714 10.0402 10.0402 10.0402 8.5714 8.5714 Resistencia del bobinado a Tw,\u221e(\u2126) RTW 1.2641 2.2490 2.2490 2.2490 9.5774 9.5774 Corriente I2t (A) II2t 2.6040 2.1129 2.1129 2.1129 0.9460 0.9460 Tiempo de Corte de I2t (s) t 36.5277 66.8941 66.8941 66.8941 36.5277 36.5277 nan nan nan nan nan nan nan nan Superficie de I2t (A2/s) SI2t 247.6890 298.6405 298.6405 298.6405 32.6909 32.6909 Tiempo de Corte de I2t fijado (s) t - nuevo 15.0000 15.0000 15.0000 15.0000 15.0000 15.0000 Corriente I2t (A) II2t- nuevo 4.0636 4.4620 4.4620 4.4620 1.4763 1.4763 nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan Motor Tensi\u00f3n (V) Peso (Gr) Par max (Nm) Par RMS (Nm) I max (A) I RMS (A) Vel. Nom (rpm) nan nan nan nan nan nan nan nan Flat Brushless EC 45 50W (339287) 36 110 0.488 0.0943 4.86 0.861 3360 Flat Brushless EC 45 50W (251601) 24 110 0.822 0.0843 24.5 2.36 6700 Flat Brushless EC 45 70W (402686) 36 141 1 0.108 20.7 1.93 6330 Flat Brushless EC 45 30W (339282) 36 110 0.337 0.0666 5.38 0.849 4760 Driver nan nan nan nan nan nan nan iPOS3604MX-CAN 36 ,,, ,,, ,,, 10 (2,5s) 4 ,,, iPOS4808MX-CAN 50 ,,, ,,, ,,, 20 (2,5s) 8 ,,,"},{"location":"tables.html#motores-transmision","title":"Motores: transmision","text":"<p>motores-transmision.csv</p> Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Articulaci\u00f3n Motor Polea Entrada Correa Polea Salida Dist. Entre Ejes reductora Relaci\u00f3n R. total Tobillo Sagital 251601 Optibelt ZRS 30-3M-6 OMEGA 255-3M 3 Optibelt ZRS 44-3M-6 90 mm 160 1.47 235.2 Tobillo Frontal 402686 Optibelt ZRS 26-3M-6 OMEGA 402-3M 3 Optibelt ZRS 44-3M-6 147'2 mm 160 1.69 270.4 Rodilla 402686 Optibelt ZRS 30-3M-6 OMEGA 276-3M 3 Optibelt ZRS 44-3M-6 83'9 mm 160 1.47 235.2 Cadera Frontal 402686 Optibelt ZRS 30-3M-6 OMEGA 357-3M 3 Optibelt ZRS 36-3M-6 127 mm 160 1.2 192 Cadera Sagital 339287 Optibelt ZRS 22-3M-6 OMEGA 312-3M 3 Optibelt ZRS 72-3M-6 82 mm 160 3.27 523.2 Cadera Axial 339287 Optibelt ZRS 24-3M-6 OMEGA 225-3M 6 Optibelt ZRS 60-3M-6 ???? 160 2.5 400 Cintura Frontal 251601 Optibelt ZRS 10-3M-9 OMEGA 231-3M 9 Optibelt ZRS 30-3M-9 ???? 160 3 480 Cintura Axial 251601 ----- ----- ----- ----- 160 ----- 160 Hombro Frontal 339282 ----- ----- ----- ----- 160 ----- 160 Hombro Sagital 339282 ----- ----- ----- ----- 160 ----- 160 Hombro Axial 339282 ----- ----- ----- ----- 120 ----- 120 Codo Frontal 339282 ----- ----- ----- ----- 160 ----- 160 Mu\u00f1eca Axial 339282 ----- ----- ----- ----- 120 ----- 120 Mu\u00f1eca Frontal 339282 ----- ----- ----- ----- 120 ----- 120"},{"location":"overview/index.html","title":"Software Repositories","text":""},{"location":"overview/index.html#software-repositories","title":"Software Repositories","text":"<p>The following sections contain comprehensive lists of repositories and their relation to TEO.</p> <ul> <li>PC Software</li> <li>Firmware</li> <li>Demonstration</li> <li>Research</li> <li>Development</li> </ul> <p>An updated list of repositories of the roboticslab-uc3m organization can be found in the Repository Index of the general Developer Manual. A great number of generic reusable component repositories can be found there, as well as a dedicated TEO subsection.</p>"},{"location":"overview/demonstration.html","title":"Demonstration","text":""},{"location":"overview/demonstration.html#overview-demonstration","title":"Overview: Demonstration","text":"<p>The following is a (partially complete) list of demonstration-oriented repositories.</p> <ul> <li>teo-self-presentation: Demostration of TEO presenting himself.</li> <li>teo-follow-me: A robotic face following and arm waving demo.</li> <li>teo-waiter: Robot waiter application.</li> <li>teo-demos-misc: Even more demos.</li> </ul>"},{"location":"overview/development.html","title":"Development","text":""},{"location":"overview/development.html#overview-development","title":"Overview: Development","text":"<p>There are mainly two repositories concerned with development of TEO software, which are in fact defined at roboticslab-uc3m organization level.</p> <ul> <li>developer-manual: Developer Manual for roboticslab-uc3m.</li> <li>project-generator: Project structure and file generation for roboticslab-uc3m, using templates and user CLI input.</li> </ul> <p>These in turn refer to additional documentation of TEO's hardware:</p> <ul> <li>datasheets-and-manuals: Third party datasheets, manuals, mechanical layout drawings, electronic schematics...</li> <li>teo-electronics: All sort of schematics for TEO's electronic boards.</li> </ul>"},{"location":"overview/firmware.html","title":"Firmware","text":""},{"location":"overview/firmware.html#overview-firmware","title":"Overview: Firmware","text":"<p>The robot PC device drivers are hosted at yarp-devices, and configured for TEO via teo-configuration-files. TEO uses three instances of this repository:</p> <ul> <li>manipulation: For the TEO manipulation PC (arms and head joint control, JR3 force/torque sensors).</li> <li>locomotion: For the TEO locomotion PC (legs and torso joint control, Xsens inertial sensor)</li> <li>head: For the TEO head PC (ASUS XTion Pro Live RGBD sensor, PointGrey RGB camera).</li> </ul> <p>More details on these instances and their configuration can be found in Network Information.</p> <p>Additional low-level microcontroller firmware used in TEO can be found here:</p> <ul> <li>cui-pic-firmware</li> <li>lacquey-pic-firmware (legacy)</li> <li>jr3-mbed-firmware (includes a PWM controller for the Lacquey fetch hand)</li> <li>textiles-arduino-firmware</li> <li>Dextra</li> </ul>"},{"location":"overview/pc.html","title":"PC Software","text":""},{"location":"overview/pc.html#overview-pc-software","title":"Overview: PC Software","text":"<p>The main TEO software repository intended for installing on any PC is called teo-main.</p> <p>It pulls contents from the following general repositories:</p> <ul> <li>developer-manual: Developer Manual for roboticslab-uc3m.</li> <li>project-generator: Project structure and file generation for roboticslab-uc3m, using templates and user CLI input.</li> <li>installation-guides: Centralized administration of dependency installation guides.</li> <li>openrave-yarp-plugins: OpenRAVE plugins to interface OpenRAVE with YARP.</li> <li>kinematics-dynamics: Kinematics and dynamics solvers and controllers.</li> <li>vision: Vision processing.</li> <li>speech: Text To Speech (TTS) and Automatic Speech Recognition (ASR).</li> <li>tools: Additional software tools.</li> </ul> <p>As well as the following TEO-specific repositories:</p> <ul> <li>teo-developer-manual: This TEO developer manual.</li> <li>teo-configuration-files: TEO configuration files, ranging from kinematic description files to scripts such as <code>teoSim</code>.</li> <li>teo-openrave-models: TEO OpenRAVE models.</li> </ul>"},{"location":"overview/research.html","title":"Research","text":""},{"location":"overview/research.html#overview-research","title":"Overview: Research","text":"<p>The following is a (partially complete) list of research-oriented repositories.</p> <ul> <li>textiles: Research on algorithms for garment perception and manipulation.</li> <li>xgnitive: Research on algorithms for CGDA and RIS.</li> </ul>"},{"location":"tutorial/index.html","title":"Tutorial","text":""},{"location":"tutorial/index.html#tutorial","title":"Tutorial","text":""},{"location":"tutorial/index.html#where-should-i-start","title":"Where should I start?","text":"<p>Read the Introduction section of the Developer manual: Developer Manual (Introduction)</p>"},{"location":"tutorial/index.html#minimum-installation-for-simulator","title":"Minimum installation for simulator","text":"<p>As a bare minimum to try the simulator, install the following (note: there is a shortcut via the superbuild https://github.com/roboticslab-uc3m/teo-main but let's follow this minimalistic procedure instead), each with their own dependencies:</p> <ul> <li>openrave-yarp-plugins</li> <li>teo-openrave-models</li> <li>teo-configuration-files</li> <li>tools</li> </ul>"},{"location":"tutorial/index.html#now-what-can-i-do","title":"Now what can I do?","text":"<p>Now that you have installed the basic TEO simulator, you're probably wondering what to do.</p>"},{"location":"tutorial/index.html#initializing-the-communication-server","title":"Initializing the communication server","text":"<p>Our current implementation uses YARP for communication. Basic use of YARP requires the use of a centralized server. This server associates the low-level implementation of the communication ports with the names we give them. Before executing any TEO program or application, please launch a YARP server from a terminal:</p> <pre><code>yarp server\n</code></pre>"},{"location":"tutorial/index.html#launching-the-simulator-through-the-terminal","title":"Launching the simulator through the terminal","text":"<p>Maintaining the YARP server open, launch the simulator from another terminal:</p> <pre><code>teoSim\n</code></pre> <p>You should get a window similar to the one depicted below.</p> <p></p> <p>Note that the setup with Dextra hands is via the <code>teoSim dextra</code> alternative command.</p>"},{"location":"tutorial/index.html#launching-the-simulator-through-the-yarp-application-manager","title":"Launching the simulator through the YARP application manager","text":"<p>It turns out to be much more practical to launch everything through the YARP application manager. Close the <code>teoSim</code> window, and instead launch the following from the terminal:</p> <pre><code>yarpmanager --from applications\n</code></pre> <p>You should get a window similar to the one depicted below. Navigate through <code>Applications</code> &gt; <code>teoSimBase_App</code> &gt; right-click on <code>teoSim</code> &gt; <code>Run</code></p> <p></p>"},{"location":"tutorial/index.html#activating-emulation-of-underactuated-hands","title":"Activating emulation of underactuated hands","text":"<p>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimBase_App</code>:</p> <ul> <li>Right-click on first <code>RealToSimControlBoard</code> &gt; <code>Run</code></li> <li>Right-click on second <code>RealToSimControlBoard</code> &gt; <code>Run</code></li> </ul> <p>You will see no action, but it will provide ports the robot hands that are more similar to the real ones.</p>"},{"location":"tutorial/index.html#spawning-objects-in-the-simulated-environment","title":"Spawning objects in the simulated environment","text":"<p>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimWorld_App</code> &gt; right-click on any <code>openraveYarpWorldClientFile</code> &gt; <code>Run</code></p> <p>Activating <code>floor</code> and <code>ironing_table</code>, you should get a window similar to the one depicted below.</p> <p></p> <p>Note that you can directly interface with the world port. While this is considered a bad practice, it is documented at: roboticslab-uc3m/openrave-yarp-plugins/libraries/OpenravePlugins/OpenraveYarpWorld</p>"},{"location":"tutorial/index.html#interfacing-with-the-robot","title":"Interfacing with the robot","text":"<p>Great news! Interfacing with the robot in simulation will be exactly the same as with the real robot! 2x1! Yay! It in fact shares common interfaces with all YARP-speaking robots! Nx1!!</p> <p>Essentially, we can interact with the robot:</p> <ol> <li>Directly talking to ports. This is considered a bad practice when APIs are available, but use cases include: fumbling around on a day just like today, speaking with a port with no API (e.g. no client network wrapper), debugging, or just plain laziness. Our own set of hacks (it's hackish because protocols may be subject to change) can be found at: yarp-tricks (from developer-manual)</li> <li>Via GUI. In certain cases, we have GUIs!</li> <li>Best practice: Within our programs and scripts, using the APIs provided by YARP. They are available in many programming languages (C++, Python, MATLAB...). Our own set of examples can be found at: examples (from yarp-devices)</li> </ol> <p>Next, continue to the dedicated sections:</p> <ul> <li>Motor Control</li> <li>RGB-D Sensor</li> <li>Mesh From Real Depth</li> <li>Scene Reconstruction</li> <li>Force/Torque Sensors</li> </ul>"},{"location":"tutorial/ft.html","title":"Force/Torque Sensors","text":""},{"location":"tutorial/ft.html#tutorial-forcetorque-sensors","title":"Tutorial: Force/Torque Sensors","text":"<p>Requires at least YARP 3.4. First, activate the <code>teoSim</code> Force/Torque Sensors: In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimBase_App</code> &gt; right-click on the <code>openraveYarpPluginLoaderClient</code> corresponding to <code>multipleanalogsensorsserver</code> &gt; <code>Run</code></p>"},{"location":"tutorial/ft.html#via-guis","title":"Via GUIs","text":"<p>To view the force/torque signals, perform the sequence:</p> <ol> <li>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimTools_App</code> &gt; right-click on the corresponding <code>yarpscope</code> &gt; <code>Run</code></li> <li>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimTools_App</code> &gt; right-click on the corresponding (bottom frame) connection &gt; <code>Connect</code></li> </ol> <p>Activate physics and move joints in <code>teoSim</code>, and you should get results similar to the figure below.</p> <p></p>"},{"location":"tutorial/ft.html#via-apis","title":"Via APIs","text":"<p>The preferred approach, using the APIs provided by YARP within our programs and scripts.</p> <ul> <li>APIs</li> <li>yarp::dev::ISixAxisForceTorqueSensors</li> <li>Implementation in simulator<ul> <li>roboticslab::YarpOpenraveAnalogSensors</li> </ul> </li> </ul>"},{"location":"tutorial/kinfu.html","title":"Scene Reconstruction","text":""},{"location":"tutorial/kinfu.html#tutorial-scene-reconstruction","title":"Tutorial: Scene Reconstruction","text":"<p>Popular RGBD cameras such as the Kinect sensor or the Intel RealSense devices can be used as 3D scanners in conjunction with free software. This tutorial explores a YARP service that runs the popular KinectFusion algorithm (as implemented in OpenCV) under the hood, then it shows how to perform proper scene reconstruction: convert a point cloud to a 3D surface with vertices and faces. The result of each step will be saved to disk so that it can be viewed and optionally processed with any 3D mesh editor such as MeshLab.</p>"},{"location":"tutorial/kinfu.html#pre-requisites","title":"Pre-requisites","text":"<p>OpenCV 4.x is the minimum version at which the OpenCV project provided a KinectFusion implementation. However, as of 4.8.0, this algorithm still remains in the contrib repository and it is hidden behind a CMake flag due to licensing limitations. Follow the instructions to build OpenCV 4.x with contrib from sources.</p> <p>During the configuration step, tell CMake how to find the contrib modules (make sure opencv/opencv_contrib was cloned):</p> <pre><code>cmake /source/dir -DOPENCV_EXTRA_MODULES_PATH=/path/to/opencv/contrib/modules\n</code></pre> <p>Also, enable those components that have special licensing (such as KinectFusion):</p> <pre><code>cmake /source/dir -DOPENCV_ENABLE_NONFREE=TRUE\n</code></pre> <p>If you can use <code>ccmake</code> to inspect the final configuration, check that <code>BUILD_opencv_rgbd</code> is set to <code>ON</code>.</p> <p>In order to perform mesh reconstruction, PCL will be used under the hood (check the installation guide).</p> <p>In order to build our components, YARP will be needed (instructions).</p> <p>Finally, clone and build our vision-related repository. If OpenCV has been correctly installed, the sceneReconstruction application should be available. In addition, also set <code>ENABLE_examples</code> to <code>ON</code> or, alternatively, build the exampleSceneReconstructionClient app independently (in examples/cpp/).</p>"},{"location":"tutorial/kinfu.html#live-3d-scanning-with-a-depth-sensor","title":"Live 3D scanning with a depth sensor","text":"<p>Once the necessary dependencies and the vision repository are installed, plug in your RGBD sensor of choice and launch the sceneReconstruction app. Since we mostly use the RealSense D435i camera, there already exists a configuration file that loads the corresponding acquisition device:</p> <pre><code>sceneReconstruction --from sceneReconstruction-realsense2.ini\n</code></pre> <p>This will open two ports (default naming unless configured otherwise): the RPC interface <code>/sceneReconstruction/rpc:s</code> and the rendered mono image <code>/sceneReconstruction/render:o</code>. Now it is advised to create a camera visor through yarpview and connect it to the render port:</p> <pre><code>yarpview --name /render\nyarp connect /sceneReconstruction/render:o /render\n</code></pre> <p>At first, it will show a blank image until the service is started. To achieve that, launch the RPC interface:</p> <pre><code>yarp rpc /sceneReconstruction/rpc:s\n</code></pre> <p>Available commands can be inspected with <code>help</code>. We need just two of them: <code>resume</code> (for starting or resuming the scene reconstruction) and <code>pause</code> (to actually generate a scene from previous frames). The workflow is as follows:</p> <ol> <li>Send a <code>resume</code> command.</li> <li>Manually scan the desired object with your camera; inspect the live render on the yarpview window for feedback.</li> <li>Once ready, send the <code>pause</code> command.</li> </ol> <p>The rendered output could look as follows:</p> <p></p> <p>Note: in the past and on certain hardware configurations, OpenCL could throw an exception related to the maximum work-group size requested by OpenCV. See this issue for an easy workaround if the issue is still present.</p>"},{"location":"tutorial/kinfu.html#offline-scene-reconstruction-from-a-point-cloud-to-a-mesh","title":"Offline scene reconstruction: from a point cloud to a mesh","text":"<p>Now, it is desirable to fetch the resulting point cloud from the generated 3D render, and reconstruct a mesh from those points. This can be achieved with the exampleSceneReconstructionClient app. Don't close the sceneReconstruction service yet (it will be queried for data).</p> <p>However, first you need to assemble a mesh reconstruction pipeline. The general procedure is described here (Markdown) and all available PCL algorithms are listed. A good start is the following configuration, to be placed in a pipeline.ini file:</p> <pre><code>[meshPipeline downsample]\nalgorithm \"VoxelGrid\"\nleafSize 0.02f\n\n[meshPipeline estimate]\nalgorithm \"NormalEstimationOMP\"\nkSearch 40\n\n[meshPipeline reconstruct]\nalgorithm \"Poisson\"\n</code></pre> <p>There are three steps in this pipeline: downsampling (not mandatory), normal estimation, mesh reconstruction. Sometimes, Poisson may fail on downsampled data, in which case this step should be removed.</p> <p>Run the following command from the vision project's build tree (the app is not installed), passing the correct path to pipeline.ini.</p> <pre><code>exampleSceneReconstructionClient --cloud cloud.ply --mesh mesh.ply --from pipeline.ini\n</code></pre> <p>The point cloud obtained through KinectFusion will be stored in binary format in cloud.ply. The resulting mesh reconstruction will be stored in mesh.ply. Launch the command with <code>--help</code> for more options.</p>"},{"location":"tutorial/kinfu.html#hints","title":"Hints","text":"<ul> <li> <p>Our sceneReconstruction service maps YARP configuration parameters (either via .ini or through command line) to KinFu options. Check the sceneReconstruction.ini file at the vision repository for current defaults. Adjust for better resolution, memory usage, scanned volume, etc.</p> </li> <li> <p>It might be interesting to defer the reconstruction process, i.e. ask the exampleSceneReconstructionClient app to only save the point cloud to disk, then perform the remaining steps by other means. Since the point cloud format used is standard (PLY), you might resort to your preferred software to obtain the final mesh from the stored cloud. If you still want to stick with PCL and our handy wrappers, there is another pair of sample apps in the vision repo for your convenience: exampleProcessCloud (in: point cloud, out: transformed/filtered/smoothened/etc. point cloud) and exampleMeshFromCloud (in: point cloud, out: mesh).</p> </li> </ul>"},{"location":"tutorial/mesh.html","title":"Mesh From Real Depth","text":""},{"location":"tutorial/mesh.html#tutorial-mesh-from-real-depth","title":"Tutorial: Mesh From Real Depth","text":"<p>It is possible to achieve some sort of mixed reality (MR) through the representation of real-world objects in the simulated environment. We'll be using a real RGB-D sensor for this purpose, piping captured depth frames through a mesh reconstruction pipeline and then loading and rendering the resulting surface mesh in the virtual world.</p> <p>Note: the techniques explained in this tutorial require the availability of a real depth sensor (ideally, the RGB-D camera on TEO's head due to involved transformations) and the compilation of YarpCloudUtils library from roboticslab-uc3m/vision with PCL support.</p> <p>Before proceeding with the following sections, make sure you have launched the real sensor. In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoBase_App</code> &gt; right-click on the <code>yarpdev</code> corresponding to <code>--context sensors</code> &gt; <code>Run</code></p>"},{"location":"tutorial/mesh.html#rendering-still-surface-meshes-from-live-rgbd","title":"Rendering still surface meshes from live RGBD","text":"<p>Objects in a real environment depicted in a single depth frame captured by the real sensor can be represented in the virtual teoSim environment following a surface reconstruction process.</p> <p>Assuming you have already launched the real sensor, in the YARP application manager instance navigate through <code>Applications</code> &gt; <code>teoSimWorld_App</code> &gt; right-click on <code>openraveYarpWorldClientMesh</code> &gt; <code>Run</code></p> <p></p>"},{"location":"tutorial/mesh.html#rendering-dynamic-surface-meshes-from-live-rgbd","title":"Rendering dynamic surface meshes from live RGBD","text":"<p>You can also take a stream of live depth frames and continuously render their reconstructed surface mesh in the virtual environment. Keep in mind this can be CPU-consuming and the quality of the resulting render highly depends on the resolution of the depth frames, the resolution of the mesh itself according to the selected parameters, and the period of the overall acquire-and-process cycle.</p> <p>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimBase_App</code> &gt; right-click on the <code>openraveYarpPluginLoaderClient</code> corresponding to the <code>YarpOpenraveMeshFromRealDepth</code> &gt; <code>Run</code></p>"},{"location":"tutorial/motor.html","title":"Motor Control","text":""},{"location":"tutorial/motor.html#tutorial-motor-control","title":"Tutorial: Motor Control","text":"<p>Throughout this section, refer to the Joint Indexes (YARP ports)  diagram to see port names and joint indexes, as well as the Joint Directions of Rotation diagram.</p>"},{"location":"tutorial/motor.html#directly-talking-to-ports","title":"Directly talking to ports","text":"<p>Recall that this is hackish and subject to change. From a terminal, connect to the limb you prefer (substitute <code>leftArm</code> following the above mentioned diagram):</p> <pre><code>yarp rpc /teoSim/leftArm/rpc:i\n</code></pre> <p>From within this, we can send joint space movements, read encoders, etc. For instance, send an absolute joint position command, to joint 0, setting the target to -25 degrees:</p> <pre><code>set pos 0 -25\n</code></pre> <p>You should in turn receive should get some kind of feedback, such as:</p> <pre><code>Response: [ok]\n</code></pre> <p>In line with the hacks mentioned above, refer to a more exhaustive list at: yarp-tricks: remote_controlboard (from developer-manual)</p>"},{"location":"tutorial/motor.html#via-guis","title":"Via GUIs","text":"<p>Two options to launch the YARP motor GUI for <code>teoSim</code>:</p> <ul> <li> <p>Via terminal:   </p><pre><code>yarpmotorgui --from yarpmotorgui/teoSim.ini\n</code></pre> </li> <li> <p>Via the application manager (better practice): Navigate through <code>Applications</code> &gt; <code>teoSimTools_App</code> &gt; right-click on <code>yarpmotorgui</code> &gt; <code>Run</code></p> </li> </ul> <p>Any of the two options, and clicking <code>OK</code> (ignore the current warnings regarding hands for now) should get you a window similar to the one depicted below.</p> <p></p>"},{"location":"tutorial/motor.html#via-apis","title":"Via APIs","text":"<p>The preferred approach, using the APIs provided by YARP within our programs and scripts.</p> <ul> <li>APIs</li> <li>The YARP motor control interfaces</li> <li>yarp::dev::IPositionControl</li> <li>yarp::dev::IVelocityControl</li> <li>yarp::dev::ITorqueControl</li> <li>yarp::dev::IEncoders</li> <li>Implementation in simulator<ul> <li>roboticslab::YarpOpenraveControlBoard</li> <li>openrave-yarp-plugins/libraries/YarpPlugins/YarpOpenraveControlBoard</li> </ul> </li> <li>Implementation in real robot<ul> <li>roboticslab::CanBusBroker</li> <li>yarp-devices/libraries/YarpPlugins/CanBusBroker</li> </ul> </li> <li>Examples (in the <code>remote</code> line, switch to <code>/teoSim/leftArm</code> or the limb of your selection)</li> <li>C++<ul> <li>yarp-devices/examples/cpp/exampleRemoteControlBoard</li> <li>yarp-devices/examples/cpp/exampleRemoteControlBoardModule</li> <li>yarp-devices/examples/cpp/examplePositionDirect</li> <li>iCub-main: Getting accustomed with motor interfaces</li> </ul> </li> <li>MATLAB<ul> <li>yarp-devices/examples/matlab/exampleRemoteControlBoard.m</li> </ul> </li> <li>Python<ul> <li>yarp-devices/examples/python/exampleRemoteControlBoard.py</li> </ul> </li> </ul>"},{"location":"tutorial/rgbd.html","title":"RGB-D Sensor","text":""},{"location":"tutorial/rgbd.html#tutorial-rgb-d-sensor","title":"Tutorial: RGB-D Sensor","text":"<p>First, activate the <code>teoSim</code> RGB-D Sensor: In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimBase_App</code> &gt; right-click on the <code>openraveYarpPluginLoaderClient</code> corresponding to <code>RGBDSensorWrapper</code> &gt; <code>Run</code></p>"},{"location":"tutorial/rgbd.html#via-guis","title":"Via GUIs","text":"<p>To view the depth image, perform the sequence:</p> <ol> <li>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimTools_App</code> &gt; right-click on the <code>yarpview</code> corresponding to the <code>depthImage</code> &gt; <code>Run</code></li> <li>In the YARP application manager instance, navigate through <code>Applications</code> &gt; <code>teoSimTools_App</code> &gt; right-click on the connection (bottom frame) corresponding to the <code>depthImage</code> &gt; <code>Connect</code></li> </ol> <p>Spawning the <code>mug</code> object as explained previously, you should get results similar to the figure below.</p> <p></p>"},{"location":"tutorial/rgbd.html#via-apis","title":"Via APIs","text":"<p>The preferred approach, using the APIs provided by YARP within our programs and scripts.</p> <ul> <li>APIs</li> <li>yarp::dev::IRGBDSensor</li> <li>Implementation in simulator<ul> <li>roboticslab::YarpOpenraveRGBDSensor</li> <li>openrave-yarp-plugins/libraries/YarpPlugins/YarpOpenraveRGBDSensor</li> </ul> </li> <li>Examples</li> <li>C++<ul> <li>vision/programs/colorRegionDetection</li> <li>vision/programs/haarDetection</li> </ul> </li> </ul>"},{"location":"tutorial/trajectories.html","title":"Trajectory Execution","text":""},{"location":"tutorial/trajectories.html#tutorial-trajectory-execution","title":"Tutorial: Trajectory Execution","text":"<p>Now that you should know how to instruct your robot to go from point A to point B in a simple motion instruction (see Tutorial: Motor Control), this tutorial will cover more complex, arbitrary multi-setpoint trajectories.</p>"},{"location":"tutorial/trajectories.html#position-controlled-high-frequency-trajectories","title":"Position-controlled high frequency trajectories","text":"<p>The most straightforward way to command a robot involves position commands since they abstract from the underlying control loops, which ultimately translate to current references applied to the motors. As opposed to having robot joints perform a steady, long transition from origin to goal, it is also interesting to follow whole paths of points defined as closely together (in terms of space and time) as possible, which would render the resulting motion smooth and highly dynamic.</p> <p>In short, this is your preferred control mode if you need to:</p> <ol> <li>traverse a list of points which are known beforehand (a.k.a. offline-based trajectories), e.g. read from a file and/or generated by an offline planner, or</li> <li>translate a \"live\" source of targets (i.e. online-based) into robot motion, acquired through a controller device such as a joystick, fetched from a visual servoing system, or generated with a time-parameterized formula, for instance.</li> </ol> <p>However, it is not a good choice whenever the distance between points is too high and/or the expected time step per instruction is close to the order of one second or more (most usually, we want to issue position commands every 10-50 milliseconds, hence the \"high frequency\"). In that case, stick to Tutorial: Motor Control and the <code>yarp::dev::IPositionControl</code> interface.</p> <p>The adequate YARP interface to achieve position-controlled high frequency trajectories is <code>yarp::dev::IPositionDirect</code>.</p>"},{"location":"tutorial/trajectories.html#methods","title":"Methods","text":"<p>We have prepared several implementations to cover most common scenarios, make sure to pick the one that best fits your needs. The current default is \"online remote push\", which is often the correct choice in terms of support for online/offline trajectories, remote launch and simulation-readiness.</p> method internalmode onlinetrajectories offlinetrajectories suitable forsimulation variableperiod launchedlocally launchedremotely examples online remote push CSP yes yes yes yes yes yes C++, Python online remote pull CSP yes no (1) yes (2) no no (1) yes C++, Python online local pull CSP yes no (1) no no yes no C++ offline synchronous ip (pt/pvt) no yes no no yes yes (4) C++, Python offline asynchronous ip (pt/pvt) no (3) yes no yes yes yes C++, Python <ul> <li>(1) Technically plausible, but either suboptimal or makes little sense since better alternatives exist.</li> <li>(2) An emulated sync port is needed, use <code>yarp clock --period value_ms --name /port</code> to stream current time at the desired rate.</li> <li>(3) Unless you really don't mind coping with noticeable delays due to having an internal buffer of points.</li> <li>(4) Make sure to configure your output port in write strict mode, or pass <code>--writeStrict on</code> to the <code>remote_controlboard</code> device.</li> </ul>"},{"location":"tutorial/trajectories.html#glossary","title":"Glossary","text":"<p>The <code>TechnosoftIpos</code> device encapsulates a collection of CANopen instructions that enable communication with the robot's iPOS drivers. We have implemented <code>yarp::dev::IPositionDirect</code> in a twofold manner:</p> <ul> <li>Cyclic synchronous position (CSP): this low-level iPOS mode assumes position commands are sent in a periodic manner - in our case, defined by the <code>syncPeriod</code> option to <code>CanBusBroker</code> (configurable; current default at time of writing is 0.02 seconds). If you choose a CSP-compliant method, an internal interpolator will adjust incoming values to avoid gaps as much as possible (thus achieving a smooth behavior) unless the command period used in your application matches said synchronization period, in which case values will be processed exactly as they are. Provided examples show how to avoid detrimental clock drifts.</li> <li>Interpolated position (ip): involves an internal setpoint buffer which depletes at a constant (synchronous) or variable (asynchronous) period. Because of said buffer and the delays it would introduce, ip is not suitable for online trajectories. Users can select one of two submodes: pt (linear interpolation) or pvt (cubic interpolation). Note that ip is considered legacy per the latest CANopen standards.</li> </ul> <p>On the above premises, implemented methods can be described as follows:</p> <ul> <li>Online remote push: CSP trajectory execution, best suited for online targets generated on the fly (but also good if loading saved setpoints from a file), can be tested on the simulator. In this case, the client application manages a timer or anything of that sort to \"push\" setpoints on a precise schedule. Said application is usually not executed aboard the robot (i.e. remote).</li> <li>Online remote pull: largely the same as above except that it is designed to connect to a remote synchronization port and send position commands in a callback fashion. The port streams current system clock at the same rate CSP expects a new setpoint. On the real robot, look for a <code>/&lt;prefix&gt;/sync:o</code> port. You can also mimick this behavior in simulation, check the footnotes for the previous table.</li> <li>Online local pull: also callback-based in the same vein, but it depends on passing a semaphore handle to <code>CanBusBroker</code>, therefore it is only suitable for applications that run on the robot board and instantiate <code>CanBusBroker</code> along with the full robot configuration. The handle you need to pass is an instance of <code>StateObserver</code>.</li> <li>Offline synchronous: depends on <code>yarp::dev::IRemoteVariables</code> to correctly configure <code>TechnosoftIpos</code> for compliance with the ip mode (docs). Solely for use in offline trajectories (e.g. loaded from file) in which all targets are expected to be reached on a fixed period (i.e. synchronously). For efficiency, you should send all those points at once, as opposed to using a timer or a <code>for</code>-loop with delays.</li> <li>Offline asynchronous: same as above, but points are sent gradually instead of in a single batch. It is allowed to have a varying period between points. Therefore, commands would be usually issued in a <code>for</code>-loop with a variable delay (i.e. asynchronously).</li> </ul>"}]}